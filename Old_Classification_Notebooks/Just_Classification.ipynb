{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# 7 MUSCLES CLASSIFICATION + (INTER/INTRA)PERSONAL VALIDATION",
   "metadata": {
    "collapsed": false
   },
   "id": "9a6d23e0d0743caa"
  },
  {
   "cell_type": "code",
   "id": "37441250891c70ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:22.468403Z",
     "start_time": "2024-05-07T15:38:22.418099Z"
    }
   },
   "source": [
    "# Installation of BioSignalsNotebooks\n",
    "# %pip install biosignalsnotebooks\n",
    "# %pip install tqdm"
   ],
   "outputs": [],
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "id": "1e2efabe2412d086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:22.640414Z",
     "start_time": "2024-05-07T15:38:22.581036Z"
    }
   },
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "# import pickle\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "# from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import biosignalsnotebooks as bsnb\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# Tensorflow Model\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import InputLayer, Conv1D, LeakyReLU, MaxPooling1D, LSTM, GlobalAveragePooling1D, Dense, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "# Weight and Biases\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "# Model Metrics\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ],
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:23.659371Z",
     "start_time": "2024-05-07T15:38:22.649147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Defining Randomness Seeds for Reproducibility\n",
    "np.random.seed(16)\n",
    "tf.random.set_seed(16)\n",
    "# Change the \n",
    "# %export TF_ENABLE_ONEDNN_OPTS=0 # for linux\n",
    "# %set TF_ENABLE_ONEDNN_OPTS=0  # for windows"
   ],
   "id": "4115f2590029044a",
   "outputs": [],
   "execution_count": 204
  },
  {
   "cell_type": "markdown",
   "source": "## Creating the sEMG Signal Dataframes from the CSV files",
   "metadata": {
    "collapsed": false
   },
   "id": "fed287a164bc3c08"
  },
  {
   "cell_type": "code",
   "source": [
    "# Defining important lists\n",
    "subjects = [\"156\", \"185\", \"186\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\"]\n",
    "muscles = ['TA', 'MG', 'SOL', 'BF', 'ST', 'VL', 'RF']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:23.684500Z",
     "start_time": "2024-05-07T15:38:23.666382Z"
    }
   },
   "id": "a3a82d6844b895f4",
   "outputs": [],
   "execution_count": 205
  },
  {
   "cell_type": "markdown",
   "source": "### Method: Using a Window size of 1000ms (including an onset of 100ms)",
   "metadata": {
    "collapsed": false
   },
   "id": "7b4bb78f5c6e1c60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:23.695026Z",
     "start_time": "2024-05-07T15:38:23.687508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window = 1000 # in ms (total window size)\n",
    "left_shift = 100 # in ms (left shift from detected onset). See detected onset on the vertical red lines in the plots above"
   ],
   "id": "860dafbbb98d697",
   "outputs": [],
   "execution_count": 206
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read TFRecords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f069e88275cf16b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:23.714035Z",
     "start_time": "2024-05-07T15:38:23.699037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate over the whole dataset to count records/samples (https://www.rustyrobotics.com/posts/tensorflow/tfdataset-record-count/)\n",
    "# Reference: https://www.rustyrobotics.com/posts/tensorflow/tfdataset-record-count/\n",
    "def countRecords(ds:tf.data.Dataset):\n",
    "\tcount = 0\n",
    "\tif tf.executing_eagerly():\n",
    "\t\t# TF v2 or v1 in eager mode\n",
    "\t\tfor _ in ds:\n",
    "\t\t\tcount = count+1\n",
    "\telse:\n",
    "\t\t# TF v1 in non-eager mode\n",
    "\t\titerator = tf.compat.v1.data.make_one_shot_iterator(ds)\n",
    "\t\tnext_batch = iterator.get_next()\n",
    "\t\twith tf.compat.v1.Session() as sess:\n",
    "\t\t\ttry:\n",
    "\t\t\t\twhile True:\n",
    "\t\t\t\t\tsess.run(next_batch)\n",
    "\t\t\t\t\tcount = count+1\n",
    "\t\t\texcept tf.errors.OutOfRangeError:\n",
    "\t\t\t\tpass\n",
    "\treturn count"
   ],
   "id": "e85f2446e9e3a817",
   "outputs": [],
   "execution_count": 207
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load TFRecords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dac32b33347666fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:23.727646Z",
     "start_time": "2024-05-07T15:38:23.716041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 1024"
   ],
   "id": "9a869b4a78f96a29",
   "outputs": [],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "source": [
    "def read_tfrecord(serialized_example, export_subject=False):\n",
    "\ttfrecord_format = (\n",
    "\t\t{\n",
    "\t\t\t'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "\t\t\t'feature': tf.io.FixedLenFeature([window], tf.float32),\n",
    "\t\t\t'subject': tf.io.FixedLenFeature([], tf.int64)\n",
    "\t\t}\n",
    "\t)\n",
    "\texample = tf.io.parse_single_example(serialized_example, tfrecord_format)\n",
    "\tf = tf.reshape(example['feature'], [window,1])\n",
    "\tf.set_shape([window, 1])\n",
    "\t# One-hot encode the label to match the expected shape for categorical_crossentropy\n",
    "\tlabel = tf.one_hot(example['label'], depth=7) \n",
    "\tif export_subject:\n",
    "\t\treturn f, label, example['subject']\n",
    "\treturn f, label\n",
    "\n",
    "def get_dataset(tf_record_name, train_or_valid):\n",
    "\t# dataset = load_dataset(filename)\n",
    "\tdataset = tf.data.TFRecordDataset(tf_record_name)\n",
    "\tdataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "\tdataset_samples = countRecords(dataset)\n",
    "\tprint(f\" - Number of {train_or_valid} Samples: \", dataset_samples)\n",
    "\tdataset = dataset.shuffle(dataset_samples)\n",
    "\tdataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\tdataset = dataset.batch(BATCH_SIZE)\n",
    "\treturn dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T15:38:23.765440Z",
     "start_time": "2024-05-07T15:38:23.731661Z"
    }
   },
   "id": "48547a8332d332b6",
   "outputs": [],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"## For Intrapersonal-CV:\")\n",
    "train_dataset = get_dataset(f'tfrecords/all_mixed_train_{window}ms.tfrecord', 'Train')\n",
    "valid_dataset = get_dataset(f'tfrecords/all_mixed_val_{window}ms.tfrecord', 'Validation')\n",
    "print(\"\\n ## For Interpersonal-LOSOCV:\")\n",
    "all_subjects_loo_data = [get_dataset(f'tfrecords/mixed_shuffled_subject_{i}_{window}ms', f\"Subject_{i}\") for i in range(1, 11)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-07T15:38:23.770453Z"
    }
   },
   "id": "6e9f683dfc88431e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## For Intrapersonal-CV:\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verifying the shapes of: LOO, Training and Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46dcef478b869dbf"
  },
  {
   "cell_type": "code",
   "source": [
    "# print('# Training:')\n",
    "# for feature, label in train_dataset:\n",
    "# \tprint(f'\\t - label={label.shape}, feature={feature.shape}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57b18567e25a41",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# print('# Validation:')\n",
    "# for feature, label in valid_dataset:\n",
    "# \tprint(f'\\t - label={label.shape}, feature={feature.shape}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22217c55fb931b9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for subj_idx, subj in enumerate(all_subjects_loo_data):\t\n",
    "# \tprint(f'# Subject_{subj_idx+1}:')\n",
    "# \tfor feature, label in subj:\n",
    "# \t\tprint(f'\\t - label={label.shape}, feature={feature.shape}')"
   ],
   "id": "9ecf6ac9c0ceacfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Useful Functions for the Training",
   "id": "ce1c5d6e9e2100a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_and_create_directory(directory):\n",
    "\t\"\"\"Check if a directory exists and clear it, then recreate it.\"\"\"\n",
    "\tif os.path.exists(directory):\n",
    "\t\t# Remove the directory and all its contents\n",
    "\t\tshutil.rmtree(directory)\n",
    "\t\tprint(f\"Old \\\"{directory}\\\" directory of the previous model deleted!\")\n",
    "\t# Create the directory again\n",
    "\tos.makedirs(directory, exist_ok=True)"
   ],
   "id": "a9de83a7dee9a4fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plotting_loss_and_accuracy_over_epochs(history_name, title, is_to_show=False):\n",
    "\th = np.load(history_name+'.npy', allow_pickle=True).item()\n",
    "\n",
    "\tmin_val_categ_crossentropy = round(min(h['val_loss']), 4)\n",
    "\tbest_v_accu = round(max(h['val_accuracy']), 3) * 100\n",
    "\n",
    "\t# Find the epoch with the best validation accuracy\n",
    "\tbest_val_acc_epoch = np.argmax(h['val_accuracy'])\n",
    "\n",
    "\tfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\tfig.suptitle(title, fontsize=18, y=0.99)\n",
    "\tax1.set_title(f'Loss Function (min_categ_crossentropy={min_val_categ_crossentropy})')\n",
    "\tax2.set_title(f'Accuracy (best_val_acc={best_v_accu}%)')\n",
    "\tax1.set(xlabel='Epoch', ylabel='Loss (Categorical Crossentropy)')\n",
    "\tax2.set(xlabel='Epoch', ylabel='Accuracy')\n",
    "\tax1.plot(h['loss'], color=\"cornflowerblue\", linewidth=3)\n",
    "\tax1.plot(h['val_loss'], color=\"lightsteelblue\", linewidth=3)\n",
    "\tax1.legend(['Training Loss', 'Validation Loss'])\n",
    "\tax2.plot(h['accuracy'], color=\"gold\", linewidth=3)\n",
    "\tax2.plot(h['val_accuracy'], color=\"darkorange\", linewidth=3)\n",
    "\tax2.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "\t# Add a red 'X' mark at the epoch where the best validation accuracy occurs\n",
    "\tax2.scatter(best_val_acc_epoch, h['val_accuracy'][best_val_acc_epoch], color='red', marker='X', s=100)\n",
    "\tplt.savefig(f\"results_figures/{title}\")\n",
    "\t\n",
    "\tif is_to_show:\n",
    "\t\tplt.show()"
   ],
   "id": "b5a571272240bff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def serializing_datasets(train_dataset_to_serialize, valid_dataset_to_serialize):\n",
    "    train_features_list = [] ; train_labels_list = []\n",
    "    valid_features_list = [] ; valid_labels_list = []\n",
    "\n",
    "    for feature_array, label_array in train_dataset_to_serialize:\n",
    "        for i in range(label_array.shape[0]):\n",
    "            train_features_list.append(feature_array[i])\n",
    "            train_labels_list.append(label_array[i])\n",
    "\t\t    \n",
    "    for feature_array, label_array in valid_dataset_to_serialize:\n",
    "        for i in range(label_array.shape[0]):\n",
    "            valid_features_list.append(feature_array[i])\n",
    "            valid_labels_list.append(label_array[i])\n",
    "\n",
    "    train_features = np.array(train_features_list); train_labels = np.array(train_labels_list)\n",
    "    valid_features = np.array(valid_features_list); valid_labels = np.array(valid_labels_list)\n",
    "    \n",
    "    return train_features, train_labels, valid_features, valid_labels"
   ],
   "id": "a7ed31e7850fd38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(x, y, color, title, is_to_show=False):\n",
    "\t# Find the filename of the best model saved during training\n",
    "\tbest_model_filename = max(glob.glob('model1/best_model_epoch_*_val_acc_*.keras'), key=os.path.getctime)\n",
    "\t# Load the best model\n",
    "\tbest_model = load_model(best_model_filename)\n",
    "\n",
    "\tpredictions_hot = best_model.predict(x)\n",
    "\tpredictions = np.argmax(predictions_hot, axis=1)\n",
    "\tnp.set_printoptions(suppress=True)\n",
    "\tprint(\"Some y Predicted\\t\", predictions[:30])\n",
    "\ty_list = np.argmax(y, axis=1)\n",
    "\tprint(\"Some y Label\\t\\t\", y_list[:30])\n",
    "\n",
    "\tcm = confusion_matrix(y_list, predictions)\n",
    "\tplt.figure(figsize=(15, 10))\n",
    "\tax = sn.heatmap(cm, annot=True, cmap=color, fmt='d')\n",
    "\tax.set_xlabel('Predicted Values')\n",
    "\tax.set_ylabel('Actual Values ')\n",
    "\tax.xaxis.set_ticklabels(['TA', 'MG', 'SOL', 'BF', 'ST', 'VL', 'RF'])\n",
    "\tax.yaxis.set_ticklabels(['TA', 'MG', 'SOL', 'BF', 'ST', 'VL', 'RF'])\n",
    "\n",
    "\tnp.set_printoptions(precision=3)\n",
    "\tprecision, recall, f1, _ = score(np.argmax(y, axis=1), np.argmax(predictions_hot, axis=1))\n",
    "\tf1_micro = f1_score(np.argmax(y, axis=1), np.argmax(predictions_hot, axis=1), average='micro')\n",
    "\tprint(f'precision: {precision}')\n",
    "\tprint(f'recall: {recall}')\n",
    "\tprint(f'fscore: {f1}')\n",
    "\tprint(f'fscore_micro: {f1_micro:.3f}')\n",
    "\n",
    "\ttitle = title + f'(F1score_micro = {f1_micro:.3})'\n",
    "\tax.set_title(title + '\\n\\n')\n",
    "\tax.xaxis.set_label_position('top')\n",
    "\tax.xaxis.set_ticks_position('top')  \n",
    "\tplt.savefig(f\"results_figures/{title}.jpg\")\n",
    "\n",
    "\tif is_to_show:\n",
    "\t\tplt.show()\n",
    "\n",
    "\treturn precision, recall, f1, f1_micro"
   ],
   "id": "fa86f0b65ec8fd58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_wrong_classification_histogram(model, x_data, y_data, title, is_to_show=False):\n",
    "\t# Ensure data is numpy array for compatibility with np.argmax and np.where\n",
    "\tpredictions = model.predict(x_data)\n",
    "\tpredicted_labels = np.argmax(predictions, axis=1)\n",
    "\tactual_labels = np.argmax(y_data, axis=1)\n",
    "\t\n",
    "\t# Making sure labels are numpy arrays\n",
    "\tif not isinstance(predicted_labels, np.ndarray):\n",
    "\t    predicted_labels = np.array(predicted_labels)\n",
    "\tif not isinstance(actual_labels, np.ndarray):\n",
    "\t    actual_labels = np.array(actual_labels)\n",
    "\t\n",
    "\t# Find incorrect indices using numpy operations\n",
    "\tincorrect_indices = np.where(predicted_labels != actual_labels)[0]\n",
    "\t\n",
    "\t# Count the frequency of each wrongly predicted muscle\n",
    "\terror_counts = {muscle: 0 for muscle in muscles}\n",
    "\tfor label in actual_labels[incorrect_indices]:\n",
    "\t    muscle_name = muscles[label]\n",
    "\t    error_counts[muscle_name] += 1\n",
    "\t\n",
    "\t# Calculate percentages\n",
    "\ttotal_incorrect = len(incorrect_indices)\n",
    "\tpercentages = [100 * count / total_incorrect for count in error_counts.values()]\n",
    "\t\n",
    "\t# Plotting\n",
    "\tsn.set(style=\"whitegrid\")\n",
    "\tplt.figure(figsize=(10, 6))\n",
    "\tbars = sn.barplot(x=list(error_counts.keys()), y=percentages, palette=\"viridis\")\n",
    "\tplt.xlabel('Muscles')\n",
    "\tplt.ylabel('Percentage of Wrong Classifications')\n",
    "\tplt.title(title)\n",
    "\tplt.xticks(rotation=45)\n",
    "\t\n",
    "\t# Adding text labels for percentages\n",
    "\tfor p, pct in zip(bars.patches, percentages):\n",
    "\t    bars.annotate(f\"{pct:.1f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "\t                  ha='center', va='center', fontsize=12, color='black', xytext=(0, 10),\n",
    "\t                  textcoords='offset points')\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f\"results_figures/{title}.jpg\")\n",
    "\t\n",
    "\tif is_to_show:\n",
    "\t\tplt.show()"
   ],
   "id": "7844129cf930f320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def display_classification_samples(model, x_data, y_data, title, num_samples_per_row=4, total_samples=12, is_to_show=False):\n",
    "\t# Make predictions\n",
    "\tpredictions = model.predict(x_data)\n",
    "\tpredicted_labels = np.argmax(predictions, axis=1)\n",
    "\tactual_labels = np.argmax(y_data, axis=1)\n",
    "\t\n",
    "\t# Find correct and incorrect indices\n",
    "\tcorrect_indices = np.where(predicted_labels == actual_labels)[0]\n",
    "\tincorrect_indices = np.where(predicted_labels != actual_labels)[0]\n",
    "\t\n",
    "\t# Select random samples from correct and incorrect classifications\n",
    "\tif len(correct_indices) > total_samples:\n",
    "\t    selected_correct = np.random.choice(correct_indices, total_samples, replace=False)\n",
    "\telse:\n",
    "\t    selected_correct = correct_indices\n",
    "\t\n",
    "\tif len(incorrect_indices) > total_samples:\n",
    "\t    selected_incorrect = np.random.choice(incorrect_indices, total_samples, replace=False)\n",
    "\telse:\n",
    "\t    selected_incorrect = incorrect_indices\n",
    "\t\n",
    "\t# Plotting\n",
    "\tfig, axes = plt.subplots(4, num_samples_per_row, figsize=(3*num_samples_per_row, 10), constrained_layout=True)\n",
    "\tfig.suptitle(title, fontsize=16)\n",
    "\t\n",
    "\t# Plot correct classifications\n",
    "\tfor row in range(2):\n",
    "\t    for idx in range(num_samples_per_row):\n",
    "\t        ax = axes[row, idx]\n",
    "\t        real_idx = idx + row * num_samples_per_row\n",
    "\t        if real_idx < len(selected_correct):\n",
    "\t            ax.plot(x_data[selected_correct[real_idx]])\n",
    "\t            ax.set_title(f\"Correct: {muscles[actual_labels[selected_correct[real_idx]]]}\", color='lime', fontsize=10)\n",
    "\t            ax.set_xlabel('Time')\n",
    "\t            ax.set_ylabel('Amplitude')\n",
    "\t            ax.grid(True)\n",
    "\t        else:\n",
    "\t            ax.set_visible(False)  # Hide unused axes\n",
    "\t\n",
    "\t# Plot incorrect classifications\n",
    "\tfor row in range(2, 4):\n",
    "\t    for idx in range(num_samples_per_row):\n",
    "\t        ax = axes[row, idx]\n",
    "\t        real_idx = idx + (row - 2) * num_samples_per_row\n",
    "\t        if real_idx < len(selected_incorrect):\n",
    "\t            ax.plot(x_data[selected_incorrect[real_idx]])\n",
    "\t            ax.set_title(f\"Wrong: {muscles[predicted_labels[selected_incorrect[real_idx]]]} (True: {muscles[actual_labels[selected_incorrect[real_idx]]]})\", color='red', fontsize=10)\n",
    "\t            ax.set_xlabel('Time')\n",
    "\t            ax.set_ylabel('Amplitude')\n",
    "\t\t        \n",
    "\tplt.savefig(f\"results_figures/{title}.jpg\")\n",
    "\tif is_to_show:\n",
    "\t\tplt.show()"
   ],
   "id": "98533334c03ec243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hybrid CNN-LSTM Model Implementation",
   "id": "106297cc060a5404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if GPU is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ],
   "id": "6f9ae9b8682270f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Definition",
   "id": "c8a7081f7b9e9281"
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# epochs = 200 # For an in depth performance testing\n",
    "epochs = 2 # For quick  testing\n",
    "\n",
    "lr = 0.01 \n",
    "scheduler = ReduceLROnPlateau(factor=0.1, patience=15, min_lr=0.0001)  # Adjust patience as needed!!!!!!!\n",
    "\n",
    "    ## CNN Layer 1\n",
    "conv1D_1 = [32,5,1]  # number_filters,kernel_size and strides \n",
    "# conv1D_1 = [64,3,1]  # number_filters,kernel_size and strides \n",
    "dropout_1= 0.3      # Dropout %\n",
    "pool1D_1 = [2,2]     # pool_size and strides\n",
    "\n",
    "    ## CNN Layer 2\n",
    "conv1D_2 = [64,7,1]  # number_filters,kernel_size and strides\n",
    "# conv1D_2 = [96,5,1]  # number_filters,kernel_size and strides\n",
    "dropout_2= 0.3      # Dropout %\n",
    "pool1D_2 = [2,2]     # pool_size and strides\n",
    "\n",
    "#     ## CNN Layer 3\n",
    "conv1D_3 = [96,9,1] # number_filters,kernel_size and strides\n",
    "# conv1D_3 = [128,9,1] # number_filters,kernel_size and strides\n",
    "dropout_3= 0.3      # Dropout %\n",
    "pool1D_3 = [2,2]     # pool_size and strides\n",
    "\n",
    "    # Dense 1\n",
    "dense_1  = 50        # nodes ->50\n",
    "dense_dropout_1 = 0.3# Dropout %\n",
    "    # LSTM 1             \n",
    "lstm_1   = 30        # lstm blocks ->30\n",
    "lstm_dropout_1 = 0.3 # Dropout %\n",
    "    # Dense 3\n",
    "dense_3  = 15        # nodes ->15\n",
    "dense_dropout_3 = 0.3# Dropout %\n",
    "\t\n",
    "def model_creation():\t\n",
    "\t# Definition\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(InputLayer((window,1))) #InputLayer(BURST_WINDOW, N_CHANNELS)\n",
    "\t\n",
    "\t# CNN LAYER 1 (Conv1D + PReLU + MaxPooling + Dropout)\n",
    "\tmodel.add(Conv1D(filters=conv1D_1[0],kernel_size=conv1D_1[1], strides=conv1D_1[2],padding='same', name='cnn_layer_1')) # TODO TRY WITH HIGHER KERNEL SIZE (ODD NUMBER!)\n",
    "\tmodel.add(LeakyReLU(negative_slope=0.1))\n",
    "\tmodel.add(MaxPooling1D(pool_size=pool1D_1[0], strides=pool1D_1[1], padding='same'))\n",
    "\t# model.add(ba)\n",
    "\tmodel.add(Dropout(dropout_1))\n",
    "\t\n",
    "\t# CNN LAYER 2 (Conv1D + PReLU + MaxPooling + Dropout)\n",
    "\tmodel.add(Conv1D(filters=conv1D_2[0], kernel_size=conv1D_2[1], strides=conv1D_2[2], padding='same', name='cnn_layer_2'))\n",
    "\tmodel.add(LeakyReLU(negative_slope=0.1))\n",
    "\tmodel.add(MaxPooling1D(pool_size=pool1D_2[0], strides=pool1D_2[1], padding='same'))\n",
    "\tmodel.add(Dropout(dropout_2))\n",
    "\t\n",
    "\t# CNN LAYER 3 (Conv1D + LeakyReLU + MaxPooling + Dropout)\n",
    "\tmodel.add(Conv1D(filters=conv1D_3[0], kernel_size=conv1D_3[1], strides=conv1D_3[2], padding='same', name='cnn_layer_3'))\n",
    "\tmodel.add(LeakyReLU(negative_slope=0.1))\n",
    "\tmodel.add(MaxPooling1D(pool_size=pool1D_3[0], strides=pool1D_3[1], padding='same'))\n",
    "\tmodel.add(Dropout(dropout_3))\n",
    "\t\n",
    "\t# Global Average Pooling\n",
    "\tmodel.add(GlobalAveragePooling1D())\n",
    "\t\n",
    "\t# Dense 1:  To integrate the Dense Layer 1 effectively after GAP, we reshape the output to make it compatible with the dense layer expectations\n",
    "\tmodel.add(Reshape((1, -1))) \n",
    "\tmodel.add(Dense(dense_1))\n",
    "\tmodel.add(LeakyReLU(negative_slope=0.1))\n",
    "\tmodel.add(Dropout(dense_dropout_1))\n",
    "\t\n",
    "\t# LSTM LAYER 1 + Dropout\n",
    "\tmodel.add(LSTM(lstm_1, dropout=lstm_dropout_1))\n",
    "\t\n",
    "\t# Dense 3\n",
    "\tmodel.add(Dense(dense_3)) \n",
    "\tmodel.add(LeakyReLU(negative_slope=0.1))\n",
    "\tmodel.add(Dropout(dense_dropout_3))\n",
    "\t\n",
    "\t# Softmax\n",
    "\tmodel.add(Dense(7, 'softmax')) # Softmax\n",
    "\t\n",
    "\tprint(\"A Fresh New Model Created!\")\n",
    "\t\n",
    "\treturn model\n",
    "\n",
    "model1 = model_creation()\n",
    "\n",
    "#Summary\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e1ce08a7df3b743",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Logging Wandb Parameters\n",
    "config = {\"number of muscles\": len(muscles),\n",
    "          \"number of subjects\": len(subjects), # used to be all_subject_dfs\n",
    "          \"LOSOCV\": \"On\",\n",
    "          \"batch_size\": BATCH_SIZE,\n",
    "          \"learning_rate\":lr,\n",
    "          \"epochs\": epochs,\n",
    "          \"scheduler\": \"ReduceLROnPlateau\",\n",
    "          \"optimizer\": \"Adam\",\n",
    "          \n",
    "          \"CNN_1\": conv1D_1,\n",
    "          \"CNN_1_Activation\": \"LeakyReLU\",\n",
    "          \"CNN_1_Pool\": pool1D_1,\n",
    "          \"CNN_1_dropout\": dropout_1,\n",
    "          \n",
    "          \"CNN_2\": conv1D_2,\n",
    "          \"CNN_2_Activation\": \"LeakyReLU\",\n",
    "          \"CNN_2_Pool\": pool1D_2,\n",
    "          \"CNN_2_dropout\": dropout_2,\n",
    "          \n",
    "          \"CNN_3\": conv1D_3,\n",
    "          \"CNN_3_Activation\": \"LeakyReLU\",\n",
    "          \"CNN_3_Pool\": pool1D_3,\n",
    "          \"CNN_3_dropout\": dropout_3,\n",
    "          \n",
    "          \"GAP\": \"On\",\n",
    "          \n",
    "          \"dense_1\": dense_1,\n",
    "          \"dense_1_dropout\": dense_dropout_1,\n",
    "          \n",
    "          \"lstm_1\": lstm_1,\n",
    "          \"lstm_1_dropout\": lstm_dropout_1,\n",
    "          \n",
    "          \"dense_3\": dense_3,\n",
    "          \"dense_3_dropout\": dense_dropout_3}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95ab9b2a04c48592",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Intrapersonal Performance Test: Cross-Validation",
   "id": "cbdcacdb559aac9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Deleting the old directories of the previously trained models\n",
    "clear_and_create_directory(\"model1\")\n",
    "clear_and_create_directory(\"histories\")\n",
    "clear_and_create_directory(\"results_figures\")"
   ],
   "id": "42fed72ce4d6e21d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialising Wandb logging\n",
    "wandb.init(project='Thesis', entity='firass-koli', config=config, name=\"Intrapersonal-CV\", group=\"Intra\")\n",
    "optimizer = Adam(learning_rate=wandb.config.learning_rate)"
   ],
   "id": "6df18b911ab67589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model1.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])  # TODO: Try DK (Learning rate)\n",
    "cp = ModelCheckpoint('model1/best_model_epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}.keras', save_best_only=True, monitor='val_accuracy', mode='max')"
   ],
   "id": "689bc06bce13a33e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "# Training the model with the wandb callback\n",
    "history = model1.fit(train_dataset, validation_data=valid_dataset, epochs=wandb.config.epochs,\n",
    "                      callbacks=[cp, scheduler, WandbMetricsLogger(log_freq=5)])\n",
    "\n",
    "# Log the best validation accuracy and loss\n",
    "wandb.log({\"best_val_accuracy\": max(history.history['val_accuracy']), \"min_val_loss\": min(history.history['val_loss'])})"
   ],
   "id": "fb5104467a5a44eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ## In case of Keyboard Interrupt\n",
    "# wandb.finish()"
   ],
   "id": "61226f8aa9e7e14d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieve minimum loss and best accuracy\n",
    "min_val_categ_crossentropy = round(min(history.history['val_loss']),3)\n",
    "best_val_accuracy = round(max(history.history['val_accuracy']),3)*100\n",
    "\n",
    "history_name = f'histories/history(val_acc={best_val_accuracy}%,val_categ_crossentropy={min_val_categ_crossentropy})'\n",
    "np.save(history_name + '.npy',history.history)\n",
    "# NOTE: The warnings you will see in the training are not relevant (it's due to the fact that the model is being saved so to be able to call it back in the future)\n",
    "print(f'History (loss and accuracy) for training and validation saved in:\\n-> {history_name}')"
   ],
   "id": "e07f3b733a5b3728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Plotting Loss and Accuracy Metrics over Epochs\n",
    "plotting_loss_and_accuracy_over_epochs(history_name, f'Loss and Accuracy over Epochs (Intrapersonal)', True)\n",
    "\n",
    "## Serializing Datasets (train and val)\n",
    "x_train, y_train, x_val, y_val = serializing_datasets(train_dataset, valid_dataset)\n",
    "\n",
    "## Metric Functions: Confusion Matrix, Precision, Recall and F-1Scores\n",
    "# Confusion Matrix in Training\n",
    "plot_confusion_matrix(x_train, y_train, 'Greens', 'Confusion Matrix of Intrapersonal Training ', is_to_show=True)\n",
    "# Confusion Matrix in Testing\n",
    "intrapersonal_precision, intrapersonal_recall, intrapersonal_f1, intrapersonal_f1_micro  =\\\n",
    "\tplot_confusion_matrix(x_val, y_val, 'Blues', 'Confusion Matrix of Intrapersonal Validation ', is_to_show=True)\n",
    "# Classification Samples\n",
    "display_classification_samples(model1, x_val, y_val, \"Classification Samples of Intrapersonal Validation\", is_to_show=True)\n",
    "# Wrong Classification %\n",
    "plot_wrong_classification_histogram(model1, x_val, y_val, \"Percentages of Wrongly Classified Muscles in Intrapersonal Validation\", is_to_show=True)"
   ],
   "id": "270273bd8ec87ea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Log the best validation accuracy and loss\n",
    "wandb.log({\"intrapersonal_best_accuracy\":  best_val_accuracy,\n",
    "           \"intrapersonal_min_val_loss\": min_val_categ_crossentropy,\n",
    "           \"intrapersonal_precision\": intrapersonal_precision,\n",
    "           \"intrapersonal_recall\": intrapersonal_recall,\n",
    "           \"intrapersonal_f1\": intrapersonal_f1,\n",
    "           \"intrapersonal_f1_micro\": intrapersonal_f1_micro})\n",
    "wandb.finish()"
   ],
   "id": "72dbc327f0f15e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interpersonal Performance Test: Leave-One-Subject-Out Cross-Validation (LOSOCV)",
   "id": "f347efd75869fe80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_subjects = len(all_subjects_loo_data)\n",
    "best_loo_validation_per_subject = [];  min_loo_val_loss_per_subject = []\n",
    "all_interpersonal_precision = []; all_interpersonal_recall = []\n",
    "all_interpersonal_f1 = []; all_interpersonal_f1_micro = []"
   ],
   "id": "a9094367d62c1de3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LOSOCV Training Loop\n",
    "for loo_subject in range(num_subjects):  # Change range to start from 0 to num_subjects-1\n",
    "\tprint(f\"Training with subject_{loo_subject+1} as a validation set\")\n",
    "\t\n",
    "\t# Deleting the old directories of the previously trained models\n",
    "\tclear_and_create_directory(\"model1\")\n",
    "\tclear_and_create_directory(\"histories\")\n",
    "\t\n",
    "\t# Initialising Wandb logging\n",
    "\twandb.init(project='Thesis', entity='firass-koli', config=config, name=f\"loo_test_subject_{loo_subject+1}\" , group=\"Inter\")\n",
    "\toptimizer = Adam(learning_rate=wandb.config.learning_rate)\n",
    "\t\n",
    "\t# Creating a new model\n",
    "\tmodel1 = model_creation()\n",
    "\t\t\n",
    "\t# Compiling the model\n",
    "\tmodel1.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
    "\t\n",
    "\t# Defining checkpoint path correctly with adjusted loo_subject index\n",
    "\tcp = ModelCheckpoint('model1/best_model_epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "\t# Prepare training and validation datasets\n",
    "\tloo_valid_dataset = all_subjects_loo_data[loo_subject]\n",
    "\tloo_train_datasets = [d for i, d in enumerate(all_subjects_loo_data) if i != loo_subject]\n",
    "\ttrain_dataset = reduce(lambda x, y: x.concatenate(y), loo_train_datasets)  # Correct concatenation using lambda\n",
    "\n",
    "\t# Train the model with the correct validation dataset\n",
    "\twith tf.device('/gpu:0'):\n",
    "\t\thistory = model1.fit(train_dataset, validation_data=loo_valid_dataset,\n",
    "\t\t\t                     epochs=wandb.config.epochs, callbacks=[cp, scheduler, WandbMetricsLogger(log_freq=5)])\n",
    "\n",
    "\t# Log the best validation accuracy and loss for each subject\n",
    "\tbest_val_accuracy = round(max(history.history['val_accuracy']),3)*100\n",
    "\tmin_val_loss = round(min(history.history['val_loss']), 3)\n",
    "\t\n",
    "\tprint(f\"Best Validation Accuracy for using Subject_{loo_subject+1} as loo: {best_val_accuracy}%\")\n",
    "\tprint(f\"Minimum Validation Loss for using Subject_{loo_subject+1} as loo: {min_val_loss}\")\n",
    "\t\n",
    "\tbest_loo_validation_per_subject.append(best_val_accuracy)\n",
    "\tmin_loo_val_loss_per_subject.append(min_val_loss)\n",
    "\n",
    "\t# Saving history\n",
    "\thistory_name = f'histories/history(val_acc={best_val_accuracy}%,val_categ_crossentropy={min_val_loss})_loo_subject_{loo_subject+1}'\n",
    "\tnp.save(history_name + '.npy',history.history)\n",
    "\n",
    "\t## Plotting Loss and Accuracy Metrics over Epochs\n",
    "\tplotting_loss_and_accuracy_over_epochs(history_name, f'Loss and Accuracy over Epochs (Interpersonal with Subject_{loo_subject+1} as loo)')\n",
    "\n",
    "\t## Metric Functions: Confusion Matrix, Precision, Recall and F-1Scores\n",
    "\t# Serializing Datasets (train and val)\n",
    "\tx_train, y_train, x_val, y_val = serializing_datasets(train_dataset,loo_valid_dataset)\n",
    "\t# Confusion Matrix in Training\n",
    "\tplot_confusion_matrix(x_train, y_train, 'Greens', f'Confusion Matrix of Interpersonal Training with Subject_{loo_subject+1} as loo')\n",
    "\t# Confusion Matrix in Testing\n",
    "\tinterpersonal_precision, interpersonal_recall, interpersonal_f1, interpersonal_f1_micro  =\\\n",
    "\t\tplot_confusion_matrix(x_val, y_val, 'Blues', f'Confusion Matrix of Interpersonal LOO_Validation on Subject_{loo_subject+1}')\n",
    "\t\n",
    "\t# Log the best validation accuracy and loss\n",
    "\twandb.log({\"interpersonal_best_val_accuracy\":  best_val_accuracy,\n",
    "\t           \"interpersonal_min_val_loss\": min_val_loss,\n",
    "\t           \"interpersonal_precision\": interpersonal_precision,\n",
    "\t           \"interpersonal_recall\": interpersonal_recall,           \n",
    "\t           \"interpersonal_f1\": interpersonal_f1,\n",
    "\t           \"interpersonal_f1_micro\": interpersonal_f1_micro})\n",
    "\twandb.finish()\n",
    "\n",
    "\tall_interpersonal_precision.append(interpersonal_precision)\n",
    "\tall_interpersonal_recall.append(interpersonal_recall)\n",
    "\tall_interpersonal_f1.append(interpersonal_f1)\n",
    "\tall_interpersonal_f1_micro.append(interpersonal_f1_micro)"
   ],
   "id": "e6ab6618ce2adc22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_interpersonal_metrics_bar(all_interpersonal_precision, all_interpersonal_recall, all_interpersonal_f1_list, all_interpersonal_f1_micro_list):\n",
    "    # Helper function to ensure metrics are single values\n",
    "    def ensure_single_value(metrics):\n",
    "        if isinstance(metrics[0], (list, np.ndarray)):  # checks if the first element is a list or ndarray\n",
    "            metrics = [np.mean(metric) for metric in metrics]\n",
    "        return metrics\n",
    "\n",
    "    # Ensuring each metric is a single value by averaging if necessary\n",
    "    all_interpersonal_precision = ensure_single_value(all_interpersonal_precision)\n",
    "    all_interpersonal_recall = ensure_single_value(all_interpersonal_recall)\n",
    "    all_interpersonal_f1_list = ensure_single_value(all_interpersonal_f1_list)\n",
    "    all_interpersonal_f1_micro_list = ensure_single_value(all_interpersonal_f1_micro_list)\n",
    "\n",
    "    subjects_names = [f\"Subject_{i+1}\" for i in range(len(all_interpersonal_precision))]\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 12)) # (15,12) before\n",
    "    fig.suptitle('Interpersonal Metrics Comparison')\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Helper function to add value labels on top of bars\n",
    "    def add_value_labels(ax):\n",
    "        for i in ax.patches:\n",
    "            ax.text(i.get_x() + i.get_width() / 2, i.get_height(), \n",
    "                    round(i.get_height(), 2), ha='center', va='bottom')\n",
    "\t\n",
    "\t# Plot each metric with rotated x-axis labels\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xticks(range(len(subjects_names)))\n",
    "        ax.set_xticklabels(subjects_names, rotation=45, ha=\"right\")  # Adjust rotation and alignment here\n",
    "\n",
    "    # Plotting Precision\n",
    "    axs[0, 0].bar(subjects_names, all_interpersonal_precision, color='b', width=bar_width)\n",
    "    axs[0, 0].set_title(f'Interpersonal Precision (Overall Precision = {round(np.mean(all_interpersonal_precision), 3)})')\n",
    "    axs[0, 0].set_xlabel('Subjects')\n",
    "    axs[0, 0].set_ylabel('Precision')\n",
    "    axs[0, 0].set_ylim([0, 1])\n",
    "    add_value_labels(axs[0, 0])\n",
    "\n",
    "    # Plotting Recall\n",
    "    axs[0, 1].bar(subjects_names, all_interpersonal_recall, color='r', width=bar_width)\n",
    "    axs[0, 1].set_title(f'Interpersonal Recall (Overall Recall = {round(np.mean(all_interpersonal_recall), 3)})')\n",
    "    axs[0, 1].set_xlabel('Subjects')\n",
    "    axs[0, 1].set_ylabel('Recall')\n",
    "    axs[0, 1].set_ylim([0, 1])\n",
    "    add_value_labels(axs[0, 1])\n",
    "\n",
    "    # Plotting F1 Score\n",
    "    axs[1, 0].bar(subjects_names, all_interpersonal_f1_list, color='g', width=bar_width)\n",
    "    axs[1, 0].set_title(f'Interpersonal F1 Score (Overall F1 Score = {round(np.mean(all_interpersonal_f1_list), 3)})')\n",
    "    axs[1, 0].set_xlabel('Subjects')\n",
    "    axs[1, 0].set_ylabel('F1 Score')\n",
    "    axs[1, 0].set_ylim([0, 1])\n",
    "    add_value_labels(axs[1, 0])\n",
    "\n",
    "    # Plotting Micro F1 Score\n",
    "    axs[1, 1].bar(subjects_names, all_interpersonal_f1_micro_list, color='c', width=bar_width)\n",
    "    axs[1, 1].set_title(f'Interpersonal F1 Micro Score (Overall F1 Micro Score = {round(np.mean(all_interpersonal_f1_micro_list), 3)})')\n",
    "    axs[1, 1].set_xlabel('Subjects')\n",
    "    axs[1, 1].set_ylabel('F1 Micro Score')\n",
    "    axs[1, 1].set_ylim([0, 1])\n",
    "    add_value_labels(axs[1, 1])\n",
    "\n",
    "    # Ensure the directory for saving figures exists\n",
    "    output_dir = \"results_figures\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Improve layout and save the figure\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(f\"{output_dir}/interpersonal_test_scores.png\")\n",
    "    plt.show()"
   ],
   "id": "b72fd7d9d81b08b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plot_interpersonal_metrics_bar(all_interpersonal_precision, all_interpersonal_recall, all_interpersonal_f1, all_interpersonal_f1_micro)"
   ],
   "id": "295cafd9c9d75191",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
