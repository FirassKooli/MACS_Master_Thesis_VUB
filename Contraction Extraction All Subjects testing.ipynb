{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO \n",
    "# IMPROVE SUBJECT DF CREATION !!!!\n",
    "# REMOVE NON NEEDED VISUALISATIONS !!!!!!!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T13:00:44.325660Z",
     "start_time": "2024-03-19T13:00:44.317364Z"
    }
   },
   "id": "57ecee5bb655c299",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37441250891c70ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:00:44.344776Z",
     "start_time": "2024-03-19T13:00:44.332211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installation of BioSignalsNotebooks\n",
    "# %pip install biosignalsnotebooks\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2efabe2412d086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:00:53.712271Z",
     "start_time": "2024-03-19T13:00:44.347001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "# import plotly.graph_objects as go\n",
    "import biosignalsnotebooks as bsnb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c2a1c3ac0dd0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:00:53.725655Z",
     "start_time": "2024-03-19T13:00:53.713784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create a dataframe to store the data of every subject across all circuits \n",
    "def subject_df_creator(subject_id):\n",
    "    circuits_dfs_list = []\n",
    "    output_msg=[]\n",
    "    for circuit_number in tqdm( range(1, 51), desc=f\"Concatenating Circuit Files for Subject AB{subject_id}\"):\n",
    "        filename = f\"5362627/AB{subject_id}/AB{subject_id}/Raw/AB{subject_id}_Circuit_0{circuit_number:02d}_raw.csv\"  \n",
    "        if not os.path.exists(filename):  # Check if the file exists\n",
    "            output_msg.append(f\"0{circuit_number:02d}\")\n",
    "            continue\n",
    "        df_circuit = pd.read_csv(filename)\n",
    "        # Dropping the Unneeded Gyroscope and Speedometer Columns \n",
    "        df_circuit = df_circuit.drop(df_circuit.columns[0:30], axis=1)\n",
    "        df_circuit = df_circuit.drop(df_circuit.columns[14:], axis=1)\n",
    "        # df_circuit['Subject'] = f\"AB{subject_id}\"\n",
    "        circuits_dfs_list.append(df_circuit)\n",
    "    \n",
    "    # Concatenate all DataFrames in the list along the rows axis\n",
    "    merged_df = pd.concat(circuits_dfs_list, ignore_index=True)\n",
    "    if output_msg: \n",
    "        print(f\"{len(output_msg)} Files do not exist:\", output_msg)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Defining important lists\n",
    "subjects = [\"156\", \"185\", \"186\", \"188\", \"189\", \"190\", \"191\", \"192\", \"193\", \"194\"]\n",
    "muscles = ['Right Tibialis Ant.', 'Left Tibialis Ant.', 'Right MG', 'Left MG', 'Right SOL', 'Left SOL', 'Right BF', 'Left BF', 'Right ST', 'Left ST', 'Right VL', 'Left VL', 'Right RF', 'Left RF']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T13:00:53.742714Z",
     "start_time": "2024-03-19T13:00:53.725655Z"
    }
   },
   "id": "aeb0b6d8fc869808",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674c2f5bcc6b8187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:01:32.895720Z",
     "start_time": "2024-03-19T13:00:53.746161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating Circuit Files for Subject AB156: 100%|██████████| 50/50 [00:13<00:00,  3.67it/s]\n",
      "Concatenating Circuit Files for Subject AB185: 100%|██████████| 50/50 [00:14<00:00,  3.48it/s]\n",
      "Concatenating Circuit Files for Subject AB186: 100%|██████████| 50/50 [00:10<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Files do not exist: ['005', '010', '020', '025', '035', '040']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframes to save subject-specific data\n",
    "df_subject_156 = subject_df_creator(\"156\")\n",
    "df_subject_185 = subject_df_creator(\"185\")\n",
    "df_subject_186 = subject_df_creator(\"186\")\n",
    "# df_subject_188 = subject_df_creator(\"188\")\n",
    "# df_subject_189 = subject_df_creator(\"189\")\n",
    "# df_subject_190 = subject_df_creator(\"190\")\n",
    "# df_subject_191 = subject_df_creator(\"191\")\n",
    "# df_subject_192 = subject_df_creator(\"192\")\n",
    "# df_subject_193 = subject_df_creator(\"193\")\n",
    "# df_subject_194 = subject_df_creator(\"194\")\n",
    "# IMPROVE !!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477e4fb02daa7f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:01:33.015101Z",
     "start_time": "2024-03-19T13:01:32.896813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging all the subject dataframes into one\n",
    "list_of_all_subjects_dfs = [df_subject_156, df_subject_185, df_subject_186 ]#, df_subject_188, df_subject_189, df_subject_190, df_subject_191, df_subject_192, df_subject_193, df_subject_194]\n",
    "df_all_subjects = pd.concat(list_of_all_subjects_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885a9899ab761bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:01:33.042512Z",
     "start_time": "2024-03-19T13:01:33.016168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Right_TA  Right_MG  Right_SOL  Right_BF  Right_ST  Right_VL  Right_RF  \\\n0 -0.110857 -0.078660  -0.077287 -0.073320 -0.107652 -0.075303 -0.069352   \n1 -0.094835 -0.069810  -0.068132 -0.071031 -0.103227 -0.072251 -0.062943   \n2 -0.083238 -0.055314  -0.057298 -0.064775 -0.096361 -0.067063 -0.055772   \n3 -0.076219 -0.051194  -0.052110 -0.059281 -0.091478 -0.066148 -0.049821   \n4 -0.071336 -0.048295  -0.049363 -0.058976 -0.093614 -0.064622 -0.049668   \n5 -0.063096 -0.038071  -0.033951 -0.053025 -0.083391 -0.060349 -0.051804   \n6 -0.058213 -0.035172  -0.034562 -0.050889 -0.083696 -0.059892 -0.050126   \n7 -0.066606 -0.040360  -0.045090 -0.059281 -0.092851 -0.063096 -0.051499   \n8 -0.082170 -0.049821  -0.059892 -0.064622 -0.101854 -0.068284 -0.053178   \n9 -0.103532 -0.062333  -0.076524 -0.070573 -0.110094 -0.074235 -0.064317   \n\n    Left_TA   Left_MG  Left_SOL   Left_BF   Left_ST   Left_VL   Left_RF  \n0 -0.092393 -0.078965 -0.091783 -0.077440 -0.089647 -0.066911 -0.066148  \n1 -0.096056 -0.074998 -0.084154 -0.089647 -0.082017 -0.062181 -0.064775  \n2 -0.096818 -0.071031 -0.082322 -0.096818 -0.074693 -0.062638 -0.068437  \n3 -0.097429 -0.069200 -0.080339 -0.099413 -0.069505 -0.058976 -0.067674  \n4 -0.093919 -0.067369 -0.074083 -0.101244 -0.071946 -0.056687 -0.067063  \n5 -0.093156 -0.068437 -0.076371 -0.112383 -0.072557 -0.060960 -0.069200  \n6 -0.093462 -0.066606 -0.075761 -0.115129 -0.074388 -0.060807 -0.071641  \n7 -0.096056 -0.063096 -0.072862 -0.108415 -0.071183 -0.060349 -0.068589  \n8 -0.098039 -0.067521 -0.078508 -0.093767 -0.074540 -0.061418 -0.072404  \n9 -0.096056 -0.073625 -0.086748 -0.083238 -0.082322 -0.061875 -0.071489  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Right_TA</th>\n      <th>Right_MG</th>\n      <th>Right_SOL</th>\n      <th>Right_BF</th>\n      <th>Right_ST</th>\n      <th>Right_VL</th>\n      <th>Right_RF</th>\n      <th>Left_TA</th>\n      <th>Left_MG</th>\n      <th>Left_SOL</th>\n      <th>Left_BF</th>\n      <th>Left_ST</th>\n      <th>Left_VL</th>\n      <th>Left_RF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.110857</td>\n      <td>-0.078660</td>\n      <td>-0.077287</td>\n      <td>-0.073320</td>\n      <td>-0.107652</td>\n      <td>-0.075303</td>\n      <td>-0.069352</td>\n      <td>-0.092393</td>\n      <td>-0.078965</td>\n      <td>-0.091783</td>\n      <td>-0.077440</td>\n      <td>-0.089647</td>\n      <td>-0.066911</td>\n      <td>-0.066148</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.094835</td>\n      <td>-0.069810</td>\n      <td>-0.068132</td>\n      <td>-0.071031</td>\n      <td>-0.103227</td>\n      <td>-0.072251</td>\n      <td>-0.062943</td>\n      <td>-0.096056</td>\n      <td>-0.074998</td>\n      <td>-0.084154</td>\n      <td>-0.089647</td>\n      <td>-0.082017</td>\n      <td>-0.062181</td>\n      <td>-0.064775</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.083238</td>\n      <td>-0.055314</td>\n      <td>-0.057298</td>\n      <td>-0.064775</td>\n      <td>-0.096361</td>\n      <td>-0.067063</td>\n      <td>-0.055772</td>\n      <td>-0.096818</td>\n      <td>-0.071031</td>\n      <td>-0.082322</td>\n      <td>-0.096818</td>\n      <td>-0.074693</td>\n      <td>-0.062638</td>\n      <td>-0.068437</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.076219</td>\n      <td>-0.051194</td>\n      <td>-0.052110</td>\n      <td>-0.059281</td>\n      <td>-0.091478</td>\n      <td>-0.066148</td>\n      <td>-0.049821</td>\n      <td>-0.097429</td>\n      <td>-0.069200</td>\n      <td>-0.080339</td>\n      <td>-0.099413</td>\n      <td>-0.069505</td>\n      <td>-0.058976</td>\n      <td>-0.067674</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.071336</td>\n      <td>-0.048295</td>\n      <td>-0.049363</td>\n      <td>-0.058976</td>\n      <td>-0.093614</td>\n      <td>-0.064622</td>\n      <td>-0.049668</td>\n      <td>-0.093919</td>\n      <td>-0.067369</td>\n      <td>-0.074083</td>\n      <td>-0.101244</td>\n      <td>-0.071946</td>\n      <td>-0.056687</td>\n      <td>-0.067063</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.063096</td>\n      <td>-0.038071</td>\n      <td>-0.033951</td>\n      <td>-0.053025</td>\n      <td>-0.083391</td>\n      <td>-0.060349</td>\n      <td>-0.051804</td>\n      <td>-0.093156</td>\n      <td>-0.068437</td>\n      <td>-0.076371</td>\n      <td>-0.112383</td>\n      <td>-0.072557</td>\n      <td>-0.060960</td>\n      <td>-0.069200</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.058213</td>\n      <td>-0.035172</td>\n      <td>-0.034562</td>\n      <td>-0.050889</td>\n      <td>-0.083696</td>\n      <td>-0.059892</td>\n      <td>-0.050126</td>\n      <td>-0.093462</td>\n      <td>-0.066606</td>\n      <td>-0.075761</td>\n      <td>-0.115129</td>\n      <td>-0.074388</td>\n      <td>-0.060807</td>\n      <td>-0.071641</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.066606</td>\n      <td>-0.040360</td>\n      <td>-0.045090</td>\n      <td>-0.059281</td>\n      <td>-0.092851</td>\n      <td>-0.063096</td>\n      <td>-0.051499</td>\n      <td>-0.096056</td>\n      <td>-0.063096</td>\n      <td>-0.072862</td>\n      <td>-0.108415</td>\n      <td>-0.071183</td>\n      <td>-0.060349</td>\n      <td>-0.068589</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.082170</td>\n      <td>-0.049821</td>\n      <td>-0.059892</td>\n      <td>-0.064622</td>\n      <td>-0.101854</td>\n      <td>-0.068284</td>\n      <td>-0.053178</td>\n      <td>-0.098039</td>\n      <td>-0.067521</td>\n      <td>-0.078508</td>\n      <td>-0.093767</td>\n      <td>-0.074540</td>\n      <td>-0.061418</td>\n      <td>-0.072404</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-0.103532</td>\n      <td>-0.062333</td>\n      <td>-0.076524</td>\n      <td>-0.070573</td>\n      <td>-0.110094</td>\n      <td>-0.074235</td>\n      <td>-0.064317</td>\n      <td>-0.096056</td>\n      <td>-0.073625</td>\n      <td>-0.086748</td>\n      <td>-0.083238</td>\n      <td>-0.082322</td>\n      <td>-0.061875</td>\n      <td>-0.071489</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_subjects[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44146ec683a0fc26",
   "metadata": {},
   "source": [
    "# Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2423d44728d53dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:01:33.047087Z",
     "start_time": "2024-03-19T13:01:33.043609Z"
    }
   },
   "outputs": [],
   "source": [
    "# # adding figures and traces\n",
    "# fig1 = go.Figure()\n",
    "# fig1.add_trace(go.Scatter(x=df_all_subjects.index/1000, y=df_all_subjects['Right_TA'][60000:90000]))\n",
    "# fig1.update_layout( title=\"sEMG Signal: Sitting Vs Contraction Bursts Vs Rest\", xaxis_title=\"Time (s)\",\n",
    "#                     yaxis_title=\"sEMG Activity (V)\", margin=dict(l=50, r=50, b=50, t=50, pad=4),\n",
    "#                     autosize=False, width=800, height=300)\n",
    "# # plotting\n",
    "# fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c58d1388c023",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5bcc96368fa6ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T13:01:33.486584Z",
     "start_time": "2024-03-19T13:01:33.049259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               Mean       Std       Var\nRight_TA  -0.103285  0.052260  0.002731\nRight_MG  -0.067029  0.040871  0.001670\nRight_SOL -0.078354  0.048994  0.002400\nRight_BF  -0.071990  0.017366  0.000302\nRight_ST  -0.108580  0.019862  0.000394\nRight_VL  -0.073812  0.035305  0.001246\nRight_RF  -0.066998  0.018185  0.000331\nLeft_TA   -0.101049  0.044580  0.001987\nLeft_MG   -0.080320  0.029920  0.000895\nLeft_SOL  -0.091904  0.030268  0.000916\nLeft_BF   -0.090289  0.020101  0.000404\nLeft_ST   -0.087812  0.022824  0.000521\nLeft_VL   -0.066145  0.027082  0.000733\nLeft_RF   -0.074933  0.018241  0.000333",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean</th>\n      <th>Std</th>\n      <th>Var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Right_TA</th>\n      <td>-0.103285</td>\n      <td>0.052260</td>\n      <td>0.002731</td>\n    </tr>\n    <tr>\n      <th>Right_MG</th>\n      <td>-0.067029</td>\n      <td>0.040871</td>\n      <td>0.001670</td>\n    </tr>\n    <tr>\n      <th>Right_SOL</th>\n      <td>-0.078354</td>\n      <td>0.048994</td>\n      <td>0.002400</td>\n    </tr>\n    <tr>\n      <th>Right_BF</th>\n      <td>-0.071990</td>\n      <td>0.017366</td>\n      <td>0.000302</td>\n    </tr>\n    <tr>\n      <th>Right_ST</th>\n      <td>-0.108580</td>\n      <td>0.019862</td>\n      <td>0.000394</td>\n    </tr>\n    <tr>\n      <th>Right_VL</th>\n      <td>-0.073812</td>\n      <td>0.035305</td>\n      <td>0.001246</td>\n    </tr>\n    <tr>\n      <th>Right_RF</th>\n      <td>-0.066998</td>\n      <td>0.018185</td>\n      <td>0.000331</td>\n    </tr>\n    <tr>\n      <th>Left_TA</th>\n      <td>-0.101049</td>\n      <td>0.044580</td>\n      <td>0.001987</td>\n    </tr>\n    <tr>\n      <th>Left_MG</th>\n      <td>-0.080320</td>\n      <td>0.029920</td>\n      <td>0.000895</td>\n    </tr>\n    <tr>\n      <th>Left_SOL</th>\n      <td>-0.091904</td>\n      <td>0.030268</td>\n      <td>0.000916</td>\n    </tr>\n    <tr>\n      <th>Left_BF</th>\n      <td>-0.090289</td>\n      <td>0.020101</td>\n      <td>0.000404</td>\n    </tr>\n    <tr>\n      <th>Left_ST</th>\n      <td>-0.087812</td>\n      <td>0.022824</td>\n      <td>0.000521</td>\n    </tr>\n    <tr>\n      <th>Left_VL</th>\n      <td>-0.066145</td>\n      <td>0.027082</td>\n      <td>0.000733</td>\n    </tr>\n    <tr>\n      <th>Left_RF</th>\n      <td>-0.074933</td>\n      <td>0.018241</td>\n      <td>0.000333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Studying mean, sigma and variance of the 14 Muscles\n",
    "df_analysis = pd.DataFrame()\n",
    "df_analysis['Mean'] = df_all_subjects.mean()\n",
    "df_analysis['Std'] = df_all_subjects.std()\n",
    "df_analysis['Var'] = df_all_subjects.var()\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8ed3bff3a2166",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-19T13:01:33.488728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All Subjects Burst Detection Progress:   0%|          | 0/42 [00:00<?, ?Muscle/s]"
     ]
    }
   ],
   "source": [
    "# Saving the detected bursts for every muscle \n",
    "sr = 1000 # sample rate = 1000Hz\n",
    "sl = 20 # smooth level (Size of sliding window used during the moving average process) #used to be 40\n",
    "th = 10 # threshold (To cover activation)\n",
    "\n",
    "# Initializing lists\n",
    "detected_bursts_right_TA = [] ; detected_bursts_left_TA = []\n",
    "detected_bursts_right_MG = [] ; detected_bursts_left_MG = []\n",
    "detected_bursts_right_SOL = []; detected_bursts_left_SOL = []\n",
    "detected_bursts_right_BF = [] ; detected_bursts_left_BF = []\n",
    "detected_bursts_right_ST = [] ; detected_bursts_left_ST = []\n",
    "detected_bursts_right_VL = [] ; detected_bursts_left_VL = []\n",
    "detected_bursts_right_RF = [] ; detected_bursts_left_RF = []\n",
    "\n",
    "\n",
    "pbar = tqdm(total=len(muscles)*len(list_of_all_subjects_dfs), desc=\"All Subjects Burst Detection Progress\", unit= \"Muscle\")\n",
    "for df_subject in list_of_all_subjects_dfs: ################# !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    ## TA\n",
    "    detected_bursts_right_TA.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_TA'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)  # Update progress bar for Right_TA\n",
    "    detected_bursts_left_TA.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_TA'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)  \n",
    "    ## MG\n",
    "    detected_bursts_right_MG.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_MG'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)  \n",
    "    detected_bursts_left_MG.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_MG'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)  \n",
    "    ## SOL\n",
    "    detected_bursts_right_SOL.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_SOL'], sample_rate=sr, smooth_level=sl,\n",
    "                                                            threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)  \n",
    "    detected_bursts_left_SOL.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_SOL'], sample_rate=sr, smooth_level=sl,\n",
    "                                                            threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    ## BF\n",
    "    detected_bursts_right_BF.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_BF'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    detected_bursts_left_BF.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_BF'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    ## ST\n",
    "    detected_bursts_right_ST.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_ST'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    detected_bursts_left_ST.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_ST'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    ## VL\n",
    "    detected_bursts_right_VL.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_VL'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    detected_bursts_left_VL.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_VL'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    ## RF\n",
    "    detected_bursts_right_RF.append(bsnb.detect_emg_activations(emg_signal=df_subject['Right_RF'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)\n",
    "    detected_bursts_left_RF.append(bsnb.detect_emg_activations(emg_signal=df_subject['Left_RF'], sample_rate=sr, smooth_level=sl,\n",
    "                                                           threshold_level=th, time_units=True, device='CH0', plot_result= False))\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff7acbdaa17cf6",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # Visualising the EMG Burst Detection for the right Tibialis Anterior\n",
    "# plot_duration = 40000 # time in milliseconds\n",
    "# bsnb.detect_emg_activations(emg_signal = df_all_subjects['Right_TA'][:plot_duration], sample_rate = sr, smooth_level=sl, threshold_level=th, time_units=True, device='CH0', plot_result= True)\n",
    "# print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb782d18a11d49",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(detected_bursts_right_TA[0:3][:10]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f73c254a64ba3c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # Visualizing First Activations -> SEE CAPTURED WINDOW WITH RESPECT OF IDENTIFIED ACTIVATION\n",
    "# duration = 8000\n",
    "# shift = 2000\n",
    "# number_bursts_to_plot = 1\n",
    "# \n",
    "# plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "# fig = plt.figure()\n",
    "# \n",
    "# plt.plot(df_all_subjects['Right_TA'][:duration], color=\"cornflowerblue\")\n",
    "# for i in range(number_bursts_to_plot): # Plot first N bursts\n",
    "#     plt.axvline(detected_bursts_right_TA[0][i]*1000,color='red', label=\"Detected Burst Region\") # ONSET VERTICAL LINE\n",
    "#     plt.axvline(detected_bursts_right_TA[1][i]*1000,color='red') # OFFSET VERTICAL LINE\n",
    "#     plt.axvline(detected_bursts_right_TA[0][i]*1000+400,color='black', label=\"Onset Window (500ms)\") # ONSET VERTICAL LINE CORRECTED (START WINDOW)\n",
    "#     plt.axvline(detected_bursts_right_TA[0][i]*1000-100,color='black') # VERTICAL LINE (END WINDOW)\n",
    "#     \n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.xlim(shift,duration)\n",
    "# plt.grid()\n",
    "# plt.xlabel('Time (ms)', fontsize=10)\n",
    "# plt.ylabel('sEMG Intensity (V)', fontsize=10)\n",
    "# \n",
    "# # plt.savefig(\"Window.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ecb5e20d3e887",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # adding figures and traces\n",
    "# fig1 = go.Figure()\n",
    "# fig1.add_trace(go.Scatter(x = df_all_subjects.index/1000 , y=df_all_subjects['Left_TA'][:10000]))\n",
    "# \n",
    "# # formatting the plot\n",
    "# fig1.update_layout(autosize=True, title=\"sEMG Signal: Detected burst and corrected onset window\",\n",
    "#                    xaxis_title=\"Time (s)\", yaxis_title=\"sEMG Activity (V)\", margin=dict(l=50, r=50, b=50, t=50, pad=4))\n",
    "# \n",
    "# fig1.add_vrect(x0=detected_bursts_right_TA[0][0], x1=detected_bursts_left_TA[1][0], row=\"all\", col=1,\n",
    "#                annotation_text=\"Detected Burst\", annotation_position=\"top right\", fillcolor=\"gray\",\n",
    "#                opacity=0.25, line_width=0)\n",
    "# \n",
    "# fig1.add_vline(x=detected_bursts_left_TA[0][0]+0.4,line_width=1.5, line_dash=\"dot\", line_color=\"red\")\n",
    "# fig1.add_vline(x=detected_bursts_left_TA[0][0]-0.1,line_width=1.5, line_dash=\"dot\", line_color=\"red\",\n",
    "#                annotation_text=\"Onset Window\",annotation_position=\"bottom right\")\n",
    "# \n",
    "# # fig1.update_xaxes(range=[7.5, 20000/1000])\n",
    "# # fig1.update_yaxes(range=[-2, 2])\n",
    "# fig1.update_layout(autosize=False, width=800, height=300)\n",
    "# # plotting\n",
    "# fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc9b4c4fbb786b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # adding figures and traces\n",
    "# fig1 = go.Figure()\n",
    "# fig1.add_trace(go.Scatter(x= df_all_subjects.index/1000, y=df_all_subjects['Right_TA']))\n",
    "# # formatting the plot\n",
    "# fig1.update_layout(autosize=True, title=\"sEMG Signal: Detection of Activation Bursts\",\n",
    "#                    xaxis_title=\"Time (s)\", yaxis_title=\"sEMG Activity (V)\",\n",
    "#                    margin=dict(l=50, r=50, b=50, t=50, pad=4))\n",
    "# \n",
    "# for i in range(len(detected_bursts_right_TA[0])):\n",
    "#     fig1.add_vrect(x0=detected_bursts_right_TA[0][i], x1=detected_bursts_right_TA[1][i], row=\"all\", col=1,\n",
    "#                    annotation_text=\"Detected Burst\", annotation_position=\"top right\",\n",
    "#                    fillcolor=\"black\", opacity=0.25, line_width=0)\n",
    "# \n",
    "# # fig1.update_xaxes(range=[30, 60])\n",
    "# fig1.update_layout(autosize=False, width=800, height=300)\n",
    "# # plotting\n",
    "# fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # adding figures and traces\n",
    "# fig1 = go.Figure()\n",
    "# fig1.add_trace(go.Scatter(x= df_all_subjects.index/1000, y=df_all_subjects['Left_ST']))\n",
    "# # formatting the plot\n",
    "# fig1.update_layout(autosize=True, title=\"sEMG Signal: Detection of Activation Bursts\",\n",
    "#                    xaxis_title=\"Time (s)\", yaxis_title=\"sEMG Activity (V)\",\n",
    "#                    margin=dict(l=50, r=50, b=50, t=50, pad=4))\n",
    "# \n",
    "# for i in range(len(detected_bursts_left_ST[0])):\n",
    "#     fig1.add_vrect(x0=detected_bursts_left_ST[0][i], x1=detected_bursts_left_ST[1][i], row=\"all\", col=1,\n",
    "#                    annotation_text=\"Detected Burst\", annotation_position=\"top right\",\n",
    "#                    fillcolor=\"black\", opacity=0.25, line_width=0)\n",
    "# \n",
    "# # fig1.update_xaxes(range=[30, 60])\n",
    "# fig1.update_layout(autosize=False, width=800, height=300)\n",
    "# # plotting\n",
    "# fig1.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "69c9c34a4b57be3b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb88282add1750",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Calculating the total number of bursts per muscle\n",
    "tot_bursts_right_TA = len(detected_bursts_right_TA[0][0]); tot_bursts_left_TA = len(detected_bursts_left_TA[0][0])\n",
    "tot_bursts_right_MG = len(detected_bursts_right_MG[0][0]); tot_bursts_left_MG = len(detected_bursts_left_MG[0][0])\n",
    "tot_bursts_right_SOL= len(detected_bursts_right_SOL[0][0]); tot_bursts_left_SOL= len(detected_bursts_left_SOL[0][0])\n",
    "tot_bursts_right_BF = len(detected_bursts_right_BF[0][0]); tot_bursts_left_BF = len(detected_bursts_left_BF[0][0])\n",
    "tot_bursts_right_ST = len(detected_bursts_right_ST[0][0]); tot_bursts_left_ST = len(detected_bursts_left_ST[0][0])\n",
    "tot_bursts_right_VL = len(detected_bursts_right_VL[0][0]); tot_bursts_left_VL = len(detected_bursts_left_VL[0][0])\n",
    "tot_bursts_right_RF = len(detected_bursts_right_RF[0][0]); tot_bursts_left_RF = len(detected_bursts_left_RF[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c90f2e398f98c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Printing the total number of bursts per muscle\n",
    "print(\"- Number of Identified Bursts:\\n\",\n",
    "      \"   Right TA:\\t\", tot_bursts_right_TA, \"\\t\", \"   Left TA:\\t\", tot_bursts_left_TA,\"\\n\",\n",
    "      \"   Right MG:\\t\", tot_bursts_right_MG, \"\\t\", \"   Left MG:\\t\", tot_bursts_left_MG,\"\\n\",\n",
    "      \"   Right SOL:\\t\", tot_bursts_right_SOL, \"\\t\", \"   Left SOL:\\t\", tot_bursts_left_SOL,\"\\n\",\n",
    "      \"   Right BF:\\t\", tot_bursts_right_BF, \"\\t\", \"   Left BF:\\t\", tot_bursts_left_BF,\"\\n\",\n",
    "      \"   Right ST:\\t\", tot_bursts_right_ST, \"\\t\", \"   Left ST:\\t\", tot_bursts_left_ST,\"\\n\",\n",
    "      \"   Right VL:\\t\", tot_bursts_right_VL, \"\\t\", \"   Left VL:\\t\", tot_bursts_left_VL,\"\\n\",\n",
    "      \"   Right RF:\\t\", tot_bursts_right_RF, \"\\t\", \"   Left RF:\\t\", tot_bursts_left_RF,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d50b477df1e2f",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Lists to store average burst length per muscle for all subjects\n",
    "average_burst_lengths_right_TA = [] ; average_burst_lengths_left_TA = []\n",
    "average_burst_lengths_right_MG = [] ; average_burst_lengths_left_MG = []\n",
    "average_burst_lengths_right_SOL = []; average_burst_lengths_left_SOL = []\n",
    "average_burst_lengths_right_BF = [] ; average_burst_lengths_left_BF = []\n",
    "average_burst_lengths_right_ST = [] ; average_burst_lengths_left_ST = []\n",
    "average_burst_lengths_right_VL = [] ; average_burst_lengths_left_VL = []\n",
    "average_burst_lengths_right_RF = [] ; average_burst_lengths_left_RF = []\n",
    "\n",
    "# Calculating average burst length per muscle\n",
    "for subject in range(len(list_of_all_subjects_dfs)):\n",
    "    ## TA\n",
    "    average_burst_lengths_right_TA.append(np.mean(np.array(detected_bursts_right_TA[subject][1])-np.array(detected_bursts_right_TA[subject][0]))*1000)\n",
    "    average_burst_lengths_left_TA.append(np.mean(np.array(detected_bursts_left_TA[subject][1])-np.array(detected_bursts_left_TA[subject][0]))*1000)\n",
    "    ## MG\n",
    "    average_burst_lengths_right_MG.append(np.mean(np.array(detected_bursts_right_MG[subject][1])-np.array(detected_bursts_right_MG[subject][0]))*1000)\n",
    "    average_burst_lengths_left_MG.append(np.mean(np.array(detected_bursts_left_MG[subject][1])-np.array(detected_bursts_left_MG[subject][0]))*1000)\n",
    "    ## SOL\n",
    "    average_burst_lengths_right_SOL.append(np.mean(np.array(detected_bursts_right_SOL[subject][1])-np.array(detected_bursts_right_SOL[subject][0]))*1000)\n",
    "    average_burst_lengths_left_SOL.append(np.mean(np.array(detected_bursts_left_SOL[subject][1])-np.array(detected_bursts_left_SOL[subject][0]))*1000)\n",
    "    ## BF\n",
    "    average_burst_lengths_right_BF.append(np.mean(np.array(detected_bursts_right_BF[subject][1])-np.array(detected_bursts_right_BF[subject][0]))*1000)\n",
    "    average_burst_lengths_left_BF.append(np.mean(np.array(detected_bursts_left_BF[subject][1])-np.array(detected_bursts_left_BF[subject][0]))*1000)\n",
    "    ## ST\n",
    "    average_burst_lengths_right_ST.append(np.mean(np.array(detected_bursts_right_ST[subject][1])-np.array(detected_bursts_right_ST[subject][0]))*1000)\n",
    "    average_burst_lengths_left_ST.append(np.mean(np.array(detected_bursts_left_ST[subject][1])-np.array(detected_bursts_left_ST[subject][0]))*1000)\n",
    "    ## VL\n",
    "    average_burst_lengths_right_VL.append(np.mean(np.array(detected_bursts_right_VL[subject][1])-np.array(detected_bursts_right_VL[subject][0]))*1000)\n",
    "    average_burst_lengths_left_VL.append(np.mean(np.array(detected_bursts_left_VL[subject][1])-np.array(detected_bursts_left_VL[subject][0]))*1000)\n",
    "    ## RF\n",
    "    average_burst_lengths_right_RF.append(np.mean(np.array(detected_bursts_right_RF[subject][1])-np.array(detected_bursts_right_RF[subject][0]))*1000)\n",
    "    average_burst_lengths_left_RF.append(np.mean(np.array(detected_bursts_left_RF[subject][1])-np.array(detected_bursts_left_RF[subject][0]))*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f9f4937b300e8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Printing average burst length per muscle\n",
    "print(\"- Avg. Length:\\n\",\n",
    "      \"   Right TA:\\t\", round(np.mean(average_burst_lengths_right_TA),2), \"ms\" , \"\\t\", \"   Left TA:\\t\", round(np.mean(average_burst_lengths_left_TA),2),\"ms\", \"\\n\",\n",
    "      \"   Right MG:\\t\", round(np.mean(average_burst_lengths_right_MG), 2), \"ms\" , \"\\t\", \"   Left MG:\\t\", round(np.mean(average_burst_lengths_left_MG), 2), \"ms\", \"\\n\",\n",
    "      \"   Right SOL:\\t\", round(np.mean(average_burst_lengths_right_SOL), 2), \"ms\" , \"\\t\", \"   Left SOL:\\t\", round(np.mean(average_burst_lengths_left_SOL), 2), \"ms\", \"\\n\",\n",
    "      \"   Right BF:\\t\", round(np.mean(average_burst_lengths_right_BF), 2), \"ms\" , \"\\t\", \"   Left BF:\\t\", round(np.mean(average_burst_lengths_left_BF), 2), \"ms\", \"\\n\",\n",
    "      \"   Right ST:\\t\", round(np.mean(average_burst_lengths_right_ST), 2), \"ms\" , \"\\t\", \"   Left ST:\\t\", round(np.mean(average_burst_lengths_left_ST), 2), \"ms\", \"\\n\",\n",
    "      \"   Right VL:\\t\", round(np.mean(average_burst_lengths_right_VL), 2), \"ms\" , \"\\t\", \"   Left VL:\\t\", round(np.mean(average_burst_lengths_left_VL), 2), \"ms\", \"\\n\",\n",
    "      \"   Right RF:\\t\", round(np.mean(average_burst_lengths_right_RF), 2), \"ms\" , \"\\t\", \"   Left RF:\\t\", round(np.mean(average_burst_lengths_left_RF), 2), \"ms\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e26385246c2544",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Adjust subplot indexing\n",
    "f, a = plt.subplots(7, 2)\n",
    "f.set_size_inches(15, 40)\n",
    "a = a.ravel()\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(subjects)))\n",
    "\n",
    "for subject_idx, subject in enumerate(subjects):\n",
    "    subject = \"subject_\"+subject\n",
    "    a[0].hist(np.array(detected_bursts_right_TA[subject_idx][1])-np.array(detected_bursts_right_TA[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[1].hist(np.array(detected_bursts_left_TA[subject_idx][1])-np.array(detected_bursts_left_TA[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx])\n",
    "\n",
    "    a[2].hist(np.array(detected_bursts_right_MG[subject_idx][1])-np.array(detected_bursts_right_MG[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[3].hist(np.array(detected_bursts_left_MG[subject_idx][1])-np.array(detected_bursts_left_MG[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx])\n",
    "\n",
    "    a[4].hist(np.array(detected_bursts_right_SOL[subject_idx][1])-np.array(detected_bursts_right_SOL[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[5].hist(np.array(detected_bursts_left_SOL[subject_idx][1])-np.array(detected_bursts_left_SOL[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx], density= True)\n",
    "\n",
    "    a[6].hist(np.array(detected_bursts_right_BF[subject_idx][1])-np.array(detected_bursts_right_BF[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[7].hist(np.array(detected_bursts_left_BF[subject_idx][1])-np.array(detected_bursts_left_BF[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx])\n",
    "\n",
    "    a[8].hist(np.array(detected_bursts_right_ST[subject_idx][1])-np.array(detected_bursts_right_ST[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[9].hist(np.array(detected_bursts_left_ST[subject_idx][1])-np.array(detected_bursts_left_ST[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx])\n",
    "\n",
    "    a[10].hist(np.array(detected_bursts_right_VL[subject_idx][1])-np.array(detected_bursts_right_VL[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[11].hist(np.array(detected_bursts_left_VL[subject_idx][1])-np.array(detected_bursts_left_VL[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx])\n",
    "\n",
    "    a[12].hist(np.array(detected_bursts_right_RF[subject_idx][1])-np.array(detected_bursts_right_RF[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" right\", color=colors[subject_idx])\n",
    "    a[13].hist(np.array(detected_bursts_left_RF[subject_idx][1])-np.array(detected_bursts_left_RF[subject_idx][0]), bins=40, alpha=0.5, label=subject + \" left\", color=colors[subject_idx])\n",
    "    \n",
    "    # Repeat similar histograms for other muscles\n",
    "\n",
    "for muscle_idx, muscle in enumerate(muscles):\n",
    "    # Set legends for each subplot\n",
    "    a[muscle_idx].legend(loc='upper right')\n",
    "\n",
    "    # Set titles for each subplot\n",
    "    a[muscle_idx].set_title('Histogram Burst Duration: ' + muscle)\n",
    "\n",
    "    # Set x and y labels for each subplot\n",
    "    a[muscle_idx].set_xlabel(\"Burst Duration (seconds)\")\n",
    "    a[muscle_idx].set_ylabel(\"Occurrences\")\n",
    "    # a[muscle_idx].\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f0ac30ba53c5",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# TODO :  REDO THIS MY WAY \n",
    "# Longest muscle bursts \n",
    "muscles = ['TA', 'MG', 'SOL', 'BF', 'ST', 'VL', 'RF']\n",
    "sides = ['right', 'left']\n",
    "\n",
    "longest_pulses = {}\n",
    "\n",
    "for muscle in muscles:\n",
    "    for side in sides:\n",
    "        bursts_variable_name = f\"detected_bursts_{side}_{muscle}\"\n",
    "        bursts = eval(bursts_variable_name)  # Use with caution; assumes variable names follow a consistent naming convention\n",
    "        \n",
    "        longest_pulse = 0  # Initialize with zero to handle empty data\n",
    "        \n",
    "        for i in range(len(bursts)):\n",
    "            pulse_durations = np.array(bursts[i][1]) - np.array(bursts[i][0])\n",
    "            current_longest_pulse = max(pulse_durations, default=0)  # Use default=0 to handle empty arrays\n",
    "            if current_longest_pulse > longest_pulse:\n",
    "                longest_pulse = current_longest_pulse\n",
    "                \n",
    "        longest_pulses[f\"{side}_{muscle}\"] = longest_pulse\n",
    "\n",
    "# Print the longest pulse for each muscle and side\n",
    "for key, value in longest_pulses.items():\n",
    "    print(f\"Longest pulse for {key}:\\t {round(value,2)} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Leave one out: Separating a Subject"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "220c511dd7f13320"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "leave_one_out = 1 # Specify which one to leave out, can also be None"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a4169ca5305ff779",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if leave_one_out is not None:\n",
    "loo_detected_bursts_right_TA = [detected_bursts_right_TA.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_TA  = [detected_bursts_left_TA.pop(leave_one_out)]\n",
    "loo_detected_bursts_right_MG = [detected_bursts_right_MG.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_MG  = [detected_bursts_left_MG.pop(leave_one_out)]\n",
    "loo_detected_bursts_right_SOL= [detected_bursts_right_SOL.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_SOL = [detected_bursts_left_SOL.pop(leave_one_out)]    \n",
    "loo_detected_bursts_right_BF = [detected_bursts_right_BF.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_BF  = [detected_bursts_left_BF.pop(leave_one_out)]\n",
    "loo_detected_bursts_right_ST = [detected_bursts_right_ST.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_ST  = [detected_bursts_left_ST.pop(leave_one_out)]\n",
    "loo_detected_bursts_right_VL = [detected_bursts_right_VL.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_VL  = [detected_bursts_left_VL.pop(leave_one_out)]\n",
    "loo_detected_bursts_right_RF = [detected_bursts_right_RF.pop(leave_one_out)]\n",
    "loo_detected_bursts_left_RF  = [detected_bursts_left_RF.pop(leave_one_out)]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d588ecd4e2b17036"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# list_of_all_subjects_dfs.pop(leave_one_out)\n",
    "# df_all_subjects = pd.concat(list_of_all_subjects_dfs, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7c94434b886bb34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loo_emg_signal_right_TA  = list(list_of_all_subjects_dfs[leave_one_out]['Right_TA'])\n",
    "loo_emg_signal_left_TA   = list(list_of_all_subjects_dfs[leave_one_out]['Left_TA'])\n",
    "loo_emg_signal_right_MG  = list(list_of_all_subjects_dfs[leave_one_out]['Right_MG'])\n",
    "loo_emg_signal_left_MG   = list(list_of_all_subjects_dfs[leave_one_out]['Left_MG'])\n",
    "loo_emg_signal_right_SOL = list(list_of_all_subjects_dfs[leave_one_out]['Right_SOL'])\n",
    "loo_emg_signal_left_SOL  = list(list_of_all_subjects_dfs[leave_one_out]['Left_SOL'])\n",
    "loo_emg_signal_right_BF  = list(list_of_all_subjects_dfs[leave_one_out]['Right_BF'])\n",
    "loo_emg_signal_left_BF   = list(list_of_all_subjects_dfs[leave_one_out]['Left_BF'])\n",
    "loo_emg_signal_right_ST  = list(list_of_all_subjects_dfs[leave_one_out]['Right_ST'])\n",
    "loo_emg_signal_left_ST   = list(list_of_all_subjects_dfs[leave_one_out]['Left_ST'])\n",
    "loo_emg_signal_right_VL  = list(list_of_all_subjects_dfs[leave_one_out]['Right_VL'])\n",
    "loo_emg_signal_left_VL   = list(list_of_all_subjects_dfs[leave_one_out]['Left_VL'])\n",
    "loo_emg_signal_right_RF  = list(list_of_all_subjects_dfs[leave_one_out]['Right_RF'])\n",
    "loo_emg_signal_left_RF   = list(list_of_all_subjects_dfs[leave_one_out]['Left_RF'])\n",
    "print(f\"{subjects[leave_one_out]} was excluded from the training!\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "322b1dac5b4becd7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# loo_emg_signal_right_TA"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3b49b7d4d7a092c3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting Bursts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969a614a9718648"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method: Preserving Onset and Window = 300ms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b4bb78f5c6e1c60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_burst_windows(muscle_emg_signal, onset_list, window_size, left_shift_value, muscle_name):\n",
    "    sampling_rate = 1000 \n",
    "    all_subjects_burst_samples = []\n",
    "    for subject_index in tqdm(range(len(onset_list)), desc=f\"Extracting Bursts for {muscle_name}\"):\n",
    "        current_subject_bursts = []\n",
    "        ii = -1\n",
    "        for onset in onset_list[subject_index][0]:\n",
    "            ii += 1\n",
    "            onset_ms = int(onset * sampling_rate) - left_shift_value\n",
    "            current_sample_window = []\n",
    "            if onset != onset_list[subject_index][0][-1]: \n",
    "                if (onset_ms + window_size) < (onset_list[subject_index][0][ii + 1] * 1000):\n",
    "                    for time_step in range(window_size):\n",
    "                        current_sample_window.append(muscle_emg_signal[onset_ms + time_step])\n",
    "            else: \n",
    "                for time_step in range(window_size):\n",
    "                    current_sample_window.append(muscle_emg_signal[onset_ms + time_step])\n",
    "\n",
    "            if current_sample_window:\n",
    "                current_subject_bursts.append(current_sample_window)\n",
    "        all_subjects_burst_samples.append(current_subject_bursts)\n",
    "    return all_subjects_burst_samples"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3d5af44622972382",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "window = 300 # in ms (total window size)\n",
    "left_shift = 50 # in ms (left shift from detected onset). See detected onset on the vertical red lines in the plots above\n",
    "\n",
    "fixed_bursts_right_TA = extract_burst_windows(df_all_subjects['Right_TA'], detected_bursts_right_TA, window, left_shift, 'Right TA')\n",
    "fixed_bursts_left_TA = extract_burst_windows(df_all_subjects['Left_TA'], detected_bursts_left_TA, window, left_shift, 'Left TA')\n",
    "fixed_bursts_right_MG = extract_burst_windows(df_all_subjects['Right_MG'], detected_bursts_right_MG, window, left_shift, 'Right MG')\n",
    "fixed_bursts_left_MG = extract_burst_windows(df_all_subjects['Left_MG'], detected_bursts_left_MG, window, left_shift, 'Left MG')\n",
    "fixed_bursts_right_SOL = extract_burst_windows(df_all_subjects['Right_SOL'], detected_bursts_right_SOL, window, left_shift, 'Right SOL')\n",
    "fixed_bursts_left_SOL = extract_burst_windows(df_all_subjects['Left_SOL'], detected_bursts_left_SOL, window, left_shift, 'Left SOL')\n",
    "fixed_bursts_right_BF = extract_burst_windows(df_all_subjects['Right_BF'], detected_bursts_right_BF, window, left_shift, 'Right BF')\n",
    "fixed_bursts_left_BF = extract_burst_windows(df_all_subjects['Left_BF'], detected_bursts_left_BF, window, left_shift, 'Left BF')\n",
    "fixed_bursts_right_ST = extract_burst_windows(df_all_subjects['Right_ST'], detected_bursts_right_ST, window, left_shift, 'Right ST')\n",
    "fixed_bursts_left_ST = extract_burst_windows(df_all_subjects['Left_ST'], detected_bursts_left_ST, window, left_shift, 'Left ST')\n",
    "fixed_bursts_right_VL = extract_burst_windows(df_all_subjects['Right_VL'], detected_bursts_right_VL, window, left_shift, 'Right VL')\n",
    "fixed_bursts_left_VL = extract_burst_windows(df_all_subjects['Left_VL'], detected_bursts_left_VL, window, left_shift, 'Left VL')\n",
    "fixed_bursts_right_RF = extract_burst_windows(df_all_subjects['Right_RF'], detected_bursts_right_RF, window, left_shift, 'Right RF')\n",
    "fixed_bursts_left_RF = extract_burst_windows(df_all_subjects['Left_RF'], detected_bursts_left_RF, window, left_shift, 'Left RF')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a917103daca3829e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Number of Muscle Bursts Per Subject (Fixed Window):\\n\",\n",
    "      \"   Right TA:\\t\", [(len(lst),) for lst in fixed_bursts_right_TA], \"\\n\", \n",
    "      \"   Left TA:\\t\", [(len(lst),) for lst in fixed_bursts_left_TA], \"\\n\",\n",
    "      \"   Right MG:\\t\", [(len(lst),) for lst in fixed_bursts_right_MG], \"\\n\", \n",
    "      \"   Left MG:\\t\", [(len(lst),) for lst in fixed_bursts_left_MG], \"\\n\",\n",
    "      \"   Right SOL:\\t\", [(len(lst),) for lst in fixed_bursts_right_SOL], \"\\n\", \n",
    "      \"   Left SOL:\\t\", [(len(lst),) for lst in fixed_bursts_left_SOL], \"\\n\",\n",
    "      \"   Right BF:\\t\", [(len(lst),) for lst in fixed_bursts_right_BF], \"\\n\", \n",
    "      \"   Left BF:\\t\", [(len(lst),) for lst in fixed_bursts_left_BF], \"\\n\",\n",
    "      \"   Right ST:\\t\", [(len(lst),) for lst in fixed_bursts_right_ST], \"\\n\", \n",
    "      \"   Left ST:\\t\", [(len(lst),) for lst in fixed_bursts_left_ST], \"\\n\",\n",
    "      \"   Right VL:\\t\", [(len(lst),) for lst in fixed_bursts_right_VL], \"\\n\", \n",
    "      \"   Left VL:\\t\", [(len(lst),) for lst in fixed_bursts_left_VL], \"\\n\",\n",
    "      \"   Right RF:\\t\", [(len(lst),) for lst in fixed_bursts_right_RF], \"\\n\", \n",
    "      \"   Left RF:\\t\", [(len(lst),) for lst in fixed_bursts_left_RF], \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c3451a51e086b681",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if leave_one_out is not None:\n",
    "loo_fixed_bursts_right_TA = extract_burst_windows(loo_emg_signal_right_TA, loo_detected_bursts_right_TA, window, left_shift, 'Leave one Out: Right TA')[0]\n",
    "loo_fixed_bursts_left_TA = extract_burst_windows(loo_emg_signal_left_TA, loo_detected_bursts_left_TA, window, left_shift, 'Leave one Out: Left TA')[0]\n",
    "loo_fixed_bursts_right_MG = extract_burst_windows(loo_emg_signal_right_MG, loo_detected_bursts_right_MG, window, left_shift, 'Leave one Out: Right MG')[0]\n",
    "loo_fixed_bursts_left_MG = extract_burst_windows(loo_emg_signal_left_MG, loo_detected_bursts_left_MG, window, left_shift, 'Leave one Out: Left MG')[0]\n",
    "loo_fixed_bursts_right_SOL = extract_burst_windows(loo_emg_signal_right_SOL, loo_detected_bursts_right_SOL, window, left_shift, 'Leave one Out: Right SOL')[0]\n",
    "loo_fixed_bursts_left_SOL = extract_burst_windows(loo_emg_signal_left_SOL, loo_detected_bursts_left_SOL, window, left_shift, 'Leave one Out: Left SOL')[0]\n",
    "loo_fixed_bursts_right_BF = extract_burst_windows(loo_emg_signal_right_BF, loo_detected_bursts_right_BF, window, left_shift, 'Leave one Out: Right BF')[0]\n",
    "loo_fixed_bursts_left_BF = extract_burst_windows(loo_emg_signal_left_BF, loo_detected_bursts_left_BF, window, left_shift, 'Leave one Out: Left BF')[0]\n",
    "loo_fixed_bursts_right_ST = extract_burst_windows(loo_emg_signal_right_ST, loo_detected_bursts_right_ST, window, left_shift, 'Leave one Out: Right ST')[0]\n",
    "loo_fixed_bursts_left_ST = extract_burst_windows(loo_emg_signal_left_ST, loo_detected_bursts_left_ST, window, left_shift, 'Leave one Out: Left ST')[0]\n",
    "loo_fixed_bursts_right_VL = extract_burst_windows(loo_emg_signal_right_VL, loo_detected_bursts_right_VL, window, left_shift, 'Leave one Out: Right VL')[0]\n",
    "loo_fixed_bursts_left_VL = extract_burst_windows(loo_emg_signal_left_VL, loo_detected_bursts_left_VL, window, left_shift, 'Leave one Out: Left VL')[0]\n",
    "loo_fixed_bursts_right_RF = extract_burst_windows(loo_emg_signal_right_RF, loo_detected_bursts_right_RF, window, left_shift, 'Leave one Out: Right RF')[0]\n",
    "loo_fixed_bursts_left_RF = extract_burst_windows(loo_emg_signal_left_RF, loo_detected_bursts_left_RF, window, left_shift, 'Leave one Out: Left RF')[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "166b4611b9b9efe4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if leave_one_out != None:\n",
    "print(\"------------------------\\nLeave One Out: Number of Muscle Bursts (Fixed Window):\\n\",\n",
    "      \"   Right TA:\\t\", len(loo_fixed_bursts_right_TA), \"\\t\", \"   Left TA:\\t\", len(loo_fixed_bursts_left_TA), \"\\n\",\n",
    "      \"   Right MG:\\t\", len(loo_fixed_bursts_right_MG), \"\\t\", \"   Left MG:\\t\", len(loo_fixed_bursts_left_MG), \"\\n\",\n",
    "      \"   Right SOL:\\t\", len(loo_fixed_bursts_right_SOL), \"\\t\", \"   Left SOL:\\t\", len(loo_fixed_bursts_left_SOL), \"\\n\",\n",
    "      \"   Right BF:\\t\", len(loo_fixed_bursts_right_BF), \"\\t\", \"   Left BF:\\t\", len(loo_fixed_bursts_left_BF), \"\\n\",\n",
    "      \"   Right ST:\\t\", len(loo_fixed_bursts_right_ST), \"\\t\", \"   Left ST:\\t\", len(loo_fixed_bursts_left_ST), \"\\n\",\n",
    "      \"   Right VL:\\t\", len(loo_fixed_bursts_right_VL), \"\\t\", \"   Left VL:\\t\", len(loo_fixed_bursts_left_VL), \"\\n\",\n",
    "      \"   Right RF:\\t\", len(loo_fixed_bursts_right_RF), \"\\t\", \"   Left RF:\\t\", len(loo_fixed_bursts_left_RF))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4668f420d13ab812",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving Leave One Out as TFRecord"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f286616d0d666327"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loo_emg_series_complete = [\n",
    "    loo_fixed_bursts_right_TA, loo_fixed_bursts_left_TA, \n",
    "    loo_fixed_bursts_right_MG, loo_fixed_bursts_left_MG, \n",
    "    loo_fixed_bursts_right_SOL, loo_fixed_bursts_left_SOL, \n",
    "    loo_fixed_bursts_right_BF, loo_fixed_bursts_left_BF, \n",
    "    loo_fixed_bursts_right_ST, loo_fixed_bursts_left_ST, \n",
    "    loo_fixed_bursts_right_VL, loo_fixed_bursts_left_VL, \n",
    "    loo_fixed_bursts_right_RF, loo_fixed_bursts_left_RF]\n",
    "\n",
    "muscle_groups = len(loo_emg_series_complete)\n",
    "\n",
    "with tf.io.TFRecordWriter('leave_one_out.tfrecord') as tfrecord:\n",
    "    for emg_muscle in tqdm(range(muscle_groups), desc=\"Extracting dataset to TFRecords\", position=0, leave=True):\n",
    "        for sample in loo_emg_series_complete[emg_muscle]:\n",
    "            # Prepare the features for TFRecord\n",
    "            features = {\n",
    "                'label': tf.train.Feature(float_list=tf.train.FloatList(value=tf.keras.utils.to_categorical(emg_muscle, 14))),\n",
    "                'feature': tf.train.Feature(float_list=tf.train.FloatList(value=sample)),\n",
    "            }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "            tfrecord.write(example.SerializeToString())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "446945d5b52a1d41",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Iterate over the whole dataset to count records/samples (https://www.rustyrobotics.com/posts/tensorflow/tfdataset-record-count/)\n",
    "# Reference: https://www.rustyrobotics.com/posts/tensorflow/tfdataset-record-count/\n",
    "def countRecords(ds:tf.data.Dataset):\n",
    "  count = 0\n",
    "  if tf.executing_eagerly():\n",
    "    # TF v2 or v1 in eager mode\n",
    "    for _ in ds:\n",
    "      count = count+1\n",
    "  else:  \n",
    "    # TF v1 in non-eager mode\n",
    "    iterator = tf.compat.v1.data.make_one_shot_iterator(ds)\n",
    "    next_batch = iterator.get_next()\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "      try:\n",
    "        while True:\n",
    "          sess.run(next_batch)\n",
    "          count = count+1    \n",
    "      except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "  return count"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a59c8c83f517a6df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 1024\n",
    "window = 300\n",
    "\n",
    "def loo_read_tfrecord(serialized_example):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'label': tf.io.FixedLenFeature([14], tf.float32),  # Adjusted for one-hot encoded labels\n",
    "            'feature': tf.io.FixedLenFeature([300], tf.float32),  # Adjusted for features CHANGE LATER ON FOR TRAINING NEEDS!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        }\n",
    "    )\n",
    "    example = tf.io.parse_single_example(serialized_example, tfrecord_format)\n",
    "    f = tf.reshape(example['feature'], [window, 1])  # Reshape if needed, here it's kept for consistency\n",
    "    f.set_shape([window, 1])\n",
    "    return f, example['label']\n",
    "\n",
    "def loo_get_dataset(tf_record_name):\n",
    "    dataset = tf.data.TFRecordDataset(tf_record_name)\n",
    "    dataset = dataset.map(loo_read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    dataset_samples = countRecords(dataset)  \n",
    "    dataset = dataset.shuffle(dataset_samples)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "loo_dataset = loo_get_dataset('leave_one_out.tfrecord')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dac5107b62d433c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for feature, label in loo_dataset:\n",
    "    print('label={}, feature={}'.format(label.shape,feature.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f87c09f7fb5b6e0f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFRecords: Storing Training and Validation Datasets in Tensorflow Records\n",
    "\n",
    "Reference: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#scrollTo=_e3g9ExathXP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "966cea74ae067db9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write TFRecords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29a14369f3df0536"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def extract_burst_windows_tfrecord(emg_series_complete, onset_lists, window_size, left_shift_value):\n",
    "    # Ensure unique file names for parallel processing or repeated calls\n",
    "    file_name = 'all_dataset.tfrecord'\n",
    "    with tf.io.TFRecordWriter(file_name) as tfrecord:\n",
    "        for muscle_index in tqdm(range(len(emg_series_complete)), desc=\"Extracting dataset to TFRecords (Fixed Window)\"):\n",
    "            for subject_index in range(len(onset_lists[muscle_index])):\n",
    "                burst_count = 0\n",
    "                ii = -1\n",
    "                for onset in onset_lists[muscle_index][subject_index][0]:\n",
    "                    ii += 1\n",
    "                    onset_ms = int(onset * 1000) - left_shift_value\n",
    "                    current_sample_window = []\n",
    "                    if onset != onset_lists[muscle_index][subject_index][0][-1]: \n",
    "                        print(onset_lists[subject_index][0][ii + 1] * 1000)\n",
    "                        if (onset_ms + window_size) < (onset_lists[muscle_index][subject_index][0][ii + 1] * 1000):\n",
    "                            burst_count = burst_count + 1\n",
    "                            for time_step in range(window_size):\n",
    "                                current_sample_window.append(emg_series_complete[muscle_index][onset_ms + time_step])\n",
    "                    else: \n",
    "                        for time_step in range(window_size):\n",
    "                            current_sample_window.append(emg_series_complete[muscle_index][onset_ms + time_step])\n",
    "                        burst_count = burst_count + 1\n",
    "\n",
    "                    if current_sample_window:\n",
    "                        # Convert your sample and label to appropriate tf.train.Feature formats\n",
    "                        features = {\n",
    "                            'label': _int64_feature(muscle_index),\n",
    "                            'feature': tf.train.Feature(float_list=tf.train.FloatList(value=current_sample_window)),\n",
    "                            'subject': _int64_feature(subject_index + 1),\n",
    "                            'burst': _int64_feature(burst_count),\n",
    "                        }\n",
    "                        example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "                        tfrecord.write(example.SerializeToString())\n",
    "                    else:\n",
    "                        print(f\"Skipped a sample due to insufficient length. Muscle: {emg_muscle}, Subject: {subject_idx}, Burst: {burst_count}\")\n",
    "    return file_name"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c117173f0d7ba35a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for list_of_all_subjects_dfs\n",
    "emg_series_tot = [df_all_subjects['Left_TA'], df_all_subjects['Right_TA'], df_all_subjects['Left_MG'], df_all_subjects['Right_MG'], df_all_subjects['Left_SOL'], df_all_subjects['Right_SOL'], df_all_subjects['Left_BF'], df_all_subjects['Right_BF'], df_all_subjects['Left_ST'], df_all_subjects['Right_ST'], df_all_subjects['Left_VL'], df_all_subjects['Right_VL'], df_all_subjects['Left_RF'], df_all_subjects['Right_RF']]\n",
    "\n",
    "detected_bursts_tot = [detected_bursts_left_TA, detected_bursts_right_TA, detected_bursts_left_MG, detected_bursts_right_MG, detected_bursts_left_SOL, detected_bursts_right_SOL, detected_bursts_left_BF, detected_bursts_right_BF, detected_bursts_left_ST, detected_bursts_right_ST, detected_bursts_left_VL, detected_bursts_right_VL, detected_bursts_left_RF, detected_bursts_right_RF]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dc2b6206ee12f725",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extract_burst_windows_tfrecord(emg_series_tot, detected_bursts_tot,  window, left_shift)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fd72714d2ba35a15",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read TFRecords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36cd7747bb758a37"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def map_fn(serialized_example):\n",
    "    features = {\n",
    "        'label': tf.io.FixedLenFeature([4], tf.float32),\n",
    "        'feature_ch1': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch2': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch3': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch4': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch5': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch6': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch7': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch8': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch9': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch10': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch11': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch12': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch13': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch14': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch15': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'feature_ch16': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'subject': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'burst':  tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, features)\n",
    "    return example['label'], example['feature_ch1'], example['feature_ch2'], example['feature_ch3'], example['feature_ch4'], example['feature_ch5'], example['feature_ch6'], example['feature_ch7'], example['feature_ch8'], example['feature_ch9'], example['feature_ch10'], example['feature_ch11'], example['feature_ch12'], example['feature_ch13'], example['feature_ch14'], example['feature_ch15'], example['feature_ch16'], example['subject'], example['burst']\n",
    "\n",
    "dataset = tf.data.TFRecordDataset('all_dataset.tfrecord')\n",
    "dataset = dataset.map(map_fn)\n",
    "\n",
    "for label,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12,ch13,ch14,ch15,ch16,subject,burst in dataset:\n",
    "    print('label={}, subject={}, burst={}'.format(label,subject,burst))\n",
    "\n",
    "# plt.plot(ch1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fbdfcf030726a6e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def separate_dataset_per_subject_train_val(dataset, subj, train_percentage):\n",
    "    # Filtering whole dataset TFRECORDS by subjects:\n",
    "    dataset_subject = dataset.filter(lambda label,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12,ch13,ch14,ch15,ch16,subject,burst: subject==subj)\n",
    "    # Count Total Samples for each Subject Dataset\n",
    "    dataset_subject_samples = countRecords(dataset_subject)\n",
    "    # Shuffling bursts per subject\n",
    "    dataset_subject_shuffled = dataset_subject.shuffle(dataset_subject_samples)\n",
    "    # Separating Subject Training and Evaluation Datasets:\n",
    "    dataset_subject_1_train = dataset_subject_shuffled.take(int(dataset_subject_samples*train_percentage))\n",
    "    dataset_subject_1_val = dataset_subject_shuffled.skip(int(dataset_subject_samples*train_percentage)).take(dataset_subject_samples - int(dataset_subject_samples*train_percentage))\n",
    "    return dataset_subject_1_train, dataset_subject_1_val\n",
    "\n",
    "train_percentage = 0.8\n",
    "dataset_subject1_train, dataset_subject1_val = separate_dataset_per_subject_train_val(dataset, 1, train_percentage)\n",
    "dataset_subject2_train, dataset_subject2_val = separate_dataset_per_subject_train_val(dataset, 2, train_percentage)\n",
    "dataset_subject3_train, dataset_subject3_val = separate_dataset_per_subject_train_val(dataset, 3, train_percentage)\n",
    "dataset_subject4_train, dataset_subject4_val = separate_dataset_per_subject_train_val(dataset, 4, train_percentage)\n",
    "dataset_subject5_train, dataset_subject5_val = separate_dataset_per_subject_train_val(dataset, 5, train_percentage)\n",
    "dataset_subject6_train, dataset_subject6_val = separate_dataset_per_subject_train_val(dataset, 6, train_percentage)\n",
    "dataset_subject7_train, dataset_subject7_val = separate_dataset_per_subject_train_val(dataset, 7, train_percentage)\n",
    "dataset_subject8_train, dataset_subject8_val = separate_dataset_per_subject_train_val(dataset, 8, train_percentage)\n",
    "    \n",
    "for label,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12,ch13,ch14,ch15,ch16,subject,burst in dataset_subject1_train.take(15):\n",
    "    print('label={}, subject={}, burst={}'.format(label,subject,burst))\n",
    "    \n",
    "# print(countRecords(dataset_subject1_train))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "44d4901cff962a30",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_subject_datasets_train = [dataset_subject1_train,\n",
    "                              dataset_subject2_train,\n",
    "                              dataset_subject3_train,\n",
    "                              dataset_subject4_train,\n",
    "                              dataset_subject5_train,\n",
    "                              dataset_subject6_train,\n",
    "                              dataset_subject7_train,\n",
    "                              dataset_subject8_train]\n",
    "\n",
    "all_subject_datasets_val =   [dataset_subject1_val,\n",
    "                              dataset_subject2_val,\n",
    "                              dataset_subject3_val,\n",
    "                              dataset_subject4_val,\n",
    "                              dataset_subject5_val,\n",
    "                              dataset_subject6_val,\n",
    "                              dataset_subject7_val,\n",
    "                              dataset_subject8_val]\n",
    "\n",
    "def augment_datasets(collection_datasets, tf_record_name):\n",
    "    with tf.io.TFRecordWriter(tf_record_name) as tfrecord:\n",
    "        for d in collection_datasets:\n",
    "            for label,ch1,ch2,ch3,ch4,ch5,ch6,ch7,ch8,ch9,ch10,ch11,ch12,ch13,ch14,ch15,ch16,subject,burst in d:\n",
    "        #         print('label={}, subject={}, burst={}'.format(label,subject,burst))\n",
    "                for i in range(16):\n",
    "                    feature = eval(eval('\"ch\" + str(i+1)'))\n",
    "                    features = {\n",
    "                        'label': tf.train.Feature(float_list=tf.train.FloatList(value=np.asarray(label))),\n",
    "                        'feature': tf.train.Feature(float_list=tf.train.FloatList(value=np.asarray(feature))),\n",
    "                        'subject': tf.train.Feature(int64_list=tf.train.Int64List(value=np.asarray([subject]))),\n",
    "                        'burst': tf.train.Feature(int64_list=tf.train.Int64List(value=np.asarray([burst]))),\n",
    "                        'channel': tf.train.Feature(int64_list=tf.train.Int64List(value=np.asarray([i+1])))\n",
    "                    }\n",
    "                    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "                    tfrecord.write(example.SerializeToString())\n",
    "    return\n",
    "\n",
    "def map_fn_final(serialized_example):\n",
    "    features = {\n",
    "        'label': tf.io.FixedLenFeature([4], tf.float32),\n",
    "        'feature': tf.io.FixedLenFeature([500], tf.float32),\n",
    "        'subject': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'burst':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'channel':  tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, features)\n",
    "    return example['label'], example['feature'], example['subject'], example['burst'], example['channel']\n",
    "\n",
    "augment_datasets(all_subject_datasets_train, 'all_mixed_train.tfrecord')\n",
    "augment_datasets(all_subject_datasets_val, 'all_mixed_val.tfrecord')\n",
    "\n",
    "def mix_and_shuffle_datasets(tf_record_name):\n",
    "    dataset = tf.data.TFRecordDataset(tf_record_name)\n",
    "    dataset = dataset.map(map_fn_final)\n",
    "    dataset_samples = countRecords(dataset)\n",
    "    dataset_final = dataset.shuffle(dataset_samples)\n",
    "    return dataset_final\n",
    "    \n",
    "dataset_final_train = mix_and_shuffle_datasets('all_mixed_train.tfrecord')\n",
    "dataset_final_val = mix_and_shuffle_datasets('all_mixed_val.tfrecord')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a48fbd91fc9f622a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for label,feature,subject,burst,channel in dataset_final_train.take(20):\n",
    "    print('label={}, feature={}, subject={}, burst={}, channel={}'.format(label,feature.shape,subject,burst,channel))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c6bceda1b350a055",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load TFRecords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74e1bc90052471de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example, export_subject=False):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            'label': tf.io.FixedLenFeature([4], tf.float32),\n",
    "            'feature': tf.io.FixedLenFeature([500], tf.float32),\n",
    "            'subject': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'burst':  tf.io.FixedLenFeature([], tf.int64),\n",
    "            'channel':  tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    )\n",
    "    example = tf.io.parse_single_example(serialized_example, tfrecord_format)\n",
    "    f = tf.reshape(example['feature'], [window,1])\n",
    "    f.set_shape([window, 1])\n",
    "    if export_subject == True:\n",
    "        return f,example['label'],example['subject']\n",
    "    return f,example['label']\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 1024\n",
    "window = 500\n",
    "\n",
    "def get_dataset(tf_record_name):\n",
    "#     dataset = load_dataset(filename)\n",
    "    dataset = tf.data.TFRecordDataset(tf_record_name)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    dataset_samples = countRecords(dataset)\n",
    "#     print(\"Samples: \", dataset_samples)\n",
    "    dataset = dataset.shuffle(dataset_samples)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6f9e9192681bcebd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = get_dataset('all_mixed_train.tfrecord')\n",
    "valid_dataset = get_dataset('all_mixed_val.tfrecord')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "84f1adc9af53835b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for feature, label in loo_dataset:\n",
    "    print('label={}, feature={}'.format(label.shape,feature.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2442f40b0f8a9a79",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Muscle Bursts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44b360a2c0a3a554"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# quick plot to see individual contraction bursts\n",
    "def plot_independent_bursts(label, burst_list, number_plots, color, fixed):\n",
    "  if number_plots > len(burst_list):\n",
    "    number_plots = len(burst_list)\n",
    "  # define plot array settings: \n",
    "  n_cols = 4\n",
    "  n_rows = math.ceil(number_plots/n_cols)\n",
    "  # plot: n_rows x n_cols of subplots\n",
    "  fig, axs = plt.subplots(n_rows, n_cols, figsize=(18,n_rows*2), dpi=150)\n",
    "  fig.suptitle('Contraction Bursts: {} ({} length)'.format(label,fixed))\n",
    "  n_burst = 0\n",
    "  for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "      if n_burst > number_plots-1:\n",
    "        break\n",
    "      if n_rows == 1: # required for the exception of only having 1 row of subplots\n",
    "        axs[j].plot(burst_list[n_burst*16][:,0], color=color)\n",
    "        axs[j].set_title('Burst {}'.format(n_burst+1))\n",
    "        n_burst+=1\n",
    "      else: # when having multiple rows of subplots\n",
    "        axs[i, j].plot(burst_list[n_burst*16][:,0], color=color)\n",
    "        axs[i, j].set_title('Burst {}'.format(n_burst+1))\n",
    "        n_burst+=1\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.set(xlabel='time (ms)', ylabel='EMG')\n",
    "      #ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "  #Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "  for ax in axs.flat:\n",
    "      ax.label_outer()\n",
    "\n",
    "plot_independent_bursts(\"Left Biceps\", fixed_bursts_left_arm, 10, \"cornflowerblue\",\"Fixed\")\n",
    "plot_independent_bursts(\"Right Biceps\", fixed_bursts_right_arm, 10, \"yellowgreen\",\"Fixed\")\n",
    "plot_independent_bursts(\"Left Tibialis Ant.\", fixed_bursts_left_leg, 10, \"orange\",\"Fixed\")\n",
    "plot_independent_bursts(\"Right Tibialis Ant.\", fixed_bursts_right_leg, 10, \"purple\",\"Fixed\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1dcb34cab3aec956",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU Test:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9183c3a7d6e55c0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
